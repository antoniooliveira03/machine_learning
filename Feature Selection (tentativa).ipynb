{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "9da89d86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T19:22:14.128875Z",
     "start_time": "2024-10-31T19:22:14.124035Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import play_song as song\n",
    "import feature_selection as fs\n",
    "import NA_outliers as n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d466540b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T19:23:27.382184Z",
     "start_time": "2024-10-31T19:23:25.327136Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age at Injury</th>\n",
       "      <th>Alternative Dispute Resolution</th>\n",
       "      <th>Attorney/Representative</th>\n",
       "      <th>Average Weekly Wage</th>\n",
       "      <th>Birth Year</th>\n",
       "      <th>Carrier Name</th>\n",
       "      <th>Carrier Type</th>\n",
       "      <th>Claim Injury Type</th>\n",
       "      <th>County of Injury</th>\n",
       "      <th>COVID-19 Indicator</th>\n",
       "      <th>District Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>IME-4 Count</th>\n",
       "      <th>Industry Code</th>\n",
       "      <th>Medical Fee Region</th>\n",
       "      <th>WCIO Cause of Injury Code</th>\n",
       "      <th>WCIO Nature of Injury Code</th>\n",
       "      <th>WCIO Part Of Body Code</th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>Number of Dependents</th>\n",
       "      <th>Accident Year</th>\n",
       "      <th>Accident Month</th>\n",
       "      <th>Accident Day</th>\n",
       "      <th>Assembly Year</th>\n",
       "      <th>Assembly Month</th>\n",
       "      <th>Assembly Day</th>\n",
       "      <th>C-2 Year</th>\n",
       "      <th>C-2 Month</th>\n",
       "      <th>C-2 Day</th>\n",
       "      <th>C-3 Date Binary</th>\n",
       "      <th>First Hearing Year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Claim Identifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5393875</th>\n",
       "      <td>31.0</td>\n",
       "      <td>571411.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>12736.0</td>\n",
       "      <td>285367.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3355.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44646.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>135885.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>13662.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5393091</th>\n",
       "      <td>46.0</td>\n",
       "      <td>571411.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1745.93</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>2862.0</td>\n",
       "      <td>285367.0</td>\n",
       "      <td>4</td>\n",
       "      <td>760.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40449.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>135885.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>14569.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5393889</th>\n",
       "      <td>40.0</td>\n",
       "      <td>571411.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1434.80</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>9126.0</td>\n",
       "      <td>285367.0</td>\n",
       "      <td>4</td>\n",
       "      <td>17450.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86171.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>85033.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12589.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5393887</th>\n",
       "      <td>61.0</td>\n",
       "      <td>571411.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>111144.0</td>\n",
       "      <td>111144.0</td>\n",
       "      <td>2</td>\n",
       "      <td>11530.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86171.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>85033.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>12603.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5393863</th>\n",
       "      <td>67.0</td>\n",
       "      <td>571411.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>14366.0</td>\n",
       "      <td>285367.0</td>\n",
       "      <td>3</td>\n",
       "      <td>60430.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60536.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>265981.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>11772.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Age at Injury  Alternative Dispute Resolution  \\\n",
       "Claim Identifier                                                  \n",
       "5393875                    31.0                        571411.0   \n",
       "5393091                    46.0                        571411.0   \n",
       "5393889                    40.0                        571411.0   \n",
       "5393887                    61.0                        571411.0   \n",
       "5393863                    67.0                        571411.0   \n",
       "\n",
       "                  Attorney/Representative  Average Weekly Wage  Birth Year  \\\n",
       "Claim Identifier                                                             \n",
       "5393875                               0.0                 0.00      1988.0   \n",
       "5393091                               1.0              1745.93      1973.0   \n",
       "5393889                               0.0              1434.80      1979.0   \n",
       "5393887                               0.0                  NaN      1958.0   \n",
       "5393863                               0.0                 0.00      1952.0   \n",
       "\n",
       "                  Carrier Name  Carrier Type  Claim Injury Type  \\\n",
       "Claim Identifier                                                  \n",
       "5393875                12736.0      285367.0                  2   \n",
       "5393091                 2862.0      285367.0                  4   \n",
       "5393889                 9126.0      285367.0                  4   \n",
       "5393887               111144.0      111144.0                  2   \n",
       "5393863                14366.0      285367.0                  3   \n",
       "\n",
       "                  County of Injury  COVID-19 Indicator  District Name  Gender  \\\n",
       "Claim Identifier                                                                \n",
       "5393875                     3355.0                 0.0        44646.0     0.0   \n",
       "5393091                      760.0                 0.0        40449.0     1.0   \n",
       "5393889                    17450.0                 0.0        86171.0     0.0   \n",
       "5393887                    11530.0                 0.0        86171.0     0.0   \n",
       "5393863                    60430.0                 0.0        60536.0     0.0   \n",
       "\n",
       "                  IME-4 Count  Industry Code  Medical Fee Region  \\\n",
       "Claim Identifier                                                   \n",
       "5393875                   0.0           44.0            135885.0   \n",
       "5393091                   4.0           23.0            135885.0   \n",
       "5393889                   0.0           56.0             85033.0   \n",
       "5393887                   0.0           62.0             85033.0   \n",
       "5393863                   0.0           44.0            265981.0   \n",
       "\n",
       "                  WCIO Cause of Injury Code  WCIO Nature of Injury Code  \\\n",
       "Claim Identifier                                                          \n",
       "5393875                                27.0                        10.0   \n",
       "5393091                                97.0                        49.0   \n",
       "5393889                                79.0                         7.0   \n",
       "5393887                                16.0                        43.0   \n",
       "5393863                                31.0                        10.0   \n",
       "\n",
       "                  WCIO Part Of Body Code  Zip Code  Number of Dependents  \\\n",
       "Claim Identifier                                                           \n",
       "5393875                             62.0   13662.0                   1.0   \n",
       "5393091                             38.0   14569.0                   4.0   \n",
       "5393889                             10.0   12589.0                   6.0   \n",
       "5393887                             36.0   12603.0                   1.0   \n",
       "5393863                             38.0   11772.0                   5.0   \n",
       "\n",
       "                  Accident Year  Accident Month  Accident Day  Assembly Year  \\\n",
       "Claim Identifier                                                               \n",
       "5393875                  2019.0            12.0          30.0           2020   \n",
       "5393091                  2019.0             8.0          30.0           2020   \n",
       "5393889                  2019.0            12.0           6.0           2020   \n",
       "5393887                  2019.0            12.0          30.0           2020   \n",
       "5393863                  2019.0            12.0          26.0           2020   \n",
       "\n",
       "                  Assembly Month  Assembly Day  C-2 Year  C-2 Month  C-2 Day  \\\n",
       "Claim Identifier                                                               \n",
       "5393875                        1             1    2019.0       12.0     31.0   \n",
       "5393091                        1             1    2020.0        1.0      1.0   \n",
       "5393889                        1             1    2020.0        1.0      1.0   \n",
       "5393887                        1             1    2019.0       12.0     31.0   \n",
       "5393863                        1             1    2019.0       12.0     31.0   \n",
       "\n",
       "                  C-3 Date Binary  First Hearing Year  \n",
       "Claim Identifier                                       \n",
       "5393875                         0                   0  \n",
       "5393091                         1                2020  \n",
       "5393889                         0                   0  \n",
       "5393887                         0                   0  \n",
       "5393863                         0                   0  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./project_data/out_eda1.csv', \n",
    "                 index_col = 'Claim Identifier')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "fb9900f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T19:23:27.395899Z",
     "start_time": "2024-10-31T19:23:27.385539Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def ball_tree_impute(df, target, n_neighbors=5):\n",
    "    # Get all features except the target column\n",
    "    features = df.columns.drop(target)\n",
    "    \n",
    "    # Separate rows with and without missing target values\n",
    "    missing_mask = df[target].isna()\n",
    "    non_missing_data = df[~missing_mask]\n",
    "    missing_data = df[missing_mask]\n",
    "\n",
    "    # Build a ball tree using all features except the target column\n",
    "    knn = NearestNeighbors(n_neighbors=n_neighbors, algorithm='ball_tree')\n",
    "    knn.fit(non_missing_data[features])\n",
    "\n",
    "    # Find nearest neighbors for rows with missing values\n",
    "    _, indices = knn.kneighbors(missing_data[features])\n",
    "\n",
    "    # Impute missing values by averaging the target values of nearest neighbors\n",
    "    imputed_values = [\n",
    "        non_missing_data.iloc[neighbor_indices][target].mean() for neighbor_indices in indices\n",
    "    ]\n",
    "    \n",
    "    # Assign the imputed values to the missing target values in the original DataFrame\n",
    "    df.loc[missing_mask, target] = imputed_values\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def custom_impute(df):\n",
    "      \n",
    "    for var_name in df.columns:\n",
    "        \n",
    "        if any(word in var_name for word in ['Year', 'Month', 'Day']) and var_name != 'Birth Year':\n",
    "                df[var_name] = df[var_name].fillna(df[var_name].median())\n",
    "        \n",
    "        if var_name == 'Birth Year':\n",
    "            # Only perform imputation for rows where both columns are not NaN and Birth Year is NaN or 0\n",
    "                mask = df['Accident Year'].notna() & df['Age at Injury'].notna()\n",
    "                df.loc[mask & (df[var_name].isna() | (df[var_name] == 0)), \n",
    "                        var_name] = df['Accident Year'] - df['Age at Injury']\n",
    "\n",
    "#                 remaining_nans = df['Birth Year'].isna().sum()\n",
    "#                 if remaining_nans > 0:\n",
    "#                     median = df[var_name].median()\n",
    "#                     df[var_name] = df[var_name].fillna(median)\n",
    "        \n",
    "        \n",
    "        # Zip Code\n",
    "        if var_name == 'Zip Code':\n",
    "            df[var_name] = df[var_name].fillna(99999)\n",
    "\n",
    "        # Wage\n",
    "        if var_name == 'Average Weekly Wage':\n",
    "            #df[var_name] = df[var_name].fillna(0)\n",
    "            df[var_name] = ball_tree_impute(df, var_name)\n",
    "\n",
    "\n",
    "        # for all 'code' variables    \n",
    "        code_columns = df.filter(regex='Code$', axis=0).columns\n",
    "        df[code_columns] = df[code_columns].fillna(0)\n",
    "\n",
    "    return df\n",
    "\n",
    "def log_transform(X):\n",
    "    return np.where(X > 0, np.log1p(X), X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "df16d13f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T19:23:33.395385Z",
     "start_time": "2024-10-31T19:23:27.398636Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 30)) while a minimum of 1 is required by NearestNeighbors.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[182], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcustom_impute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[181], line 58\u001b[0m, in \u001b[0;36mcustom_impute\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Wage\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m var_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage Weekly Wage\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;66;03m#df[var_name] = df[var_name].fillna(0)\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m     df[var_name] \u001b[38;5;241m=\u001b[39m \u001b[43mball_tree_impute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# for all 'code' variables    \u001b[39;00m\n\u001b[1;32m     62\u001b[0m code_columns \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mfilter(regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCode$\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mcolumns\n",
      "Cell \u001b[0;32mIn[181], line 19\u001b[0m, in \u001b[0;36mball_tree_impute\u001b[0;34m(df, target, n_neighbors)\u001b[0m\n\u001b[1;32m     16\u001b[0m knn\u001b[38;5;241m.\u001b[39mfit(non_missing_data[features])\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Find nearest neighbors for rows with missing values\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m _, indices \u001b[38;5;241m=\u001b[39m \u001b[43mknn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmissing_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Impute missing values by averaging the target values of nearest neighbors\u001b[39;00m\n\u001b[1;32m     22\u001b[0m imputed_values \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     23\u001b[0m     non_missing_data\u001b[38;5;241m.\u001b[39miloc[neighbor_indices][target]\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;28;01mfor\u001b[39;00m neighbor_indices \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[1;32m     24\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/envs/Text_Mining/lib/python3.10/site-packages/sklearn/neighbors/_base.py:806\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    804\u001b[0m         X \u001b[38;5;241m=\u001b[39m _check_precomputed(X)\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 806\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    808\u001b[0m n_samples_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples_fit_\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_neighbors \u001b[38;5;241m>\u001b[39m n_samples_fit:\n",
      "File \u001b[0;32m~/anaconda3/envs/Text_Mining/lib/python3.10/site-packages/sklearn/base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 565\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/anaconda3/envs/Text_Mining/lib/python3.10/site-packages/sklearn/utils/validation.py:931\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[0;32m--> 931\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    932\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    933\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    934\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[1;32m    935\u001b[0m         )\n\u001b[1;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    938\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 30)) while a minimum of 1 is required by NearestNeighbors."
     ]
    }
   ],
   "source": [
    "custom_impute(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "f2425f19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T19:22:48.190640Z",
     "start_time": "2024-10-31T19:22:48.144758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age at Injury                     0\n",
       "Alternative Dispute Resolution    0\n",
       "Attorney/Representative           0\n",
       "Average Weekly Wage               0\n",
       "Birth Year                        0\n",
       "Carrier Name                      0\n",
       "Carrier Type                      0\n",
       "Claim Injury Type                 0\n",
       "County of Injury                  0\n",
       "COVID-19 Indicator                0\n",
       "District Name                     0\n",
       "Gender                            0\n",
       "IME-4 Count                       0\n",
       "Industry Code                     0\n",
       "Medical Fee Region                0\n",
       "WCIO Cause of Injury Code         0\n",
       "WCIO Nature of Injury Code        0\n",
       "WCIO Part Of Body Code            0\n",
       "Zip Code                          0\n",
       "Number of Dependents              0\n",
       "Accident Year                     0\n",
       "Accident Month                    0\n",
       "Accident Day                      0\n",
       "Assembly Year                     0\n",
       "Assembly Month                    0\n",
       "Assembly Day                      0\n",
       "C-2 Year                          0\n",
       "C-2 Month                         0\n",
       "C-2 Day                           0\n",
       "C-3 Date Binary                   0\n",
       "First Hearing Year                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8bf3b445",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T18:43:40.646336Z",
     "start_time": "2024-10-31T18:43:40.643932Z"
    }
   },
   "outputs": [],
   "source": [
    "## EVAL function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ded98ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = ['Age at Injury', 'Average Weekly Wage', 'Birth Year', 'IME-4 Count', 'Number of Dependents',\n",
    "       'Accident Year', 'Accident Month', 'Accident Day', 'Assembly Year', 'Assembly Month', 'Assembly Day',\n",
    "       'C-2 Year', 'C-2 Month', 'C-2 Day', 'First Hearing Year']\n",
    "\n",
    "categ = ['Alternative Dispute Resolution', 'Attorney/Representative', 'Carrier Name', 'Carrier Type',\n",
    "         'County of Injury', 'COVID-19 Indicator', 'District Name', 'Gender',\n",
    "         'Industry Code', 'Medical Fee Region', 'WCIO Cause of Injury Code', 'WCIO Nature of Injury Code',\n",
    "         'WCIO Part Of Body Code', 'Zip Code', 'C-3 Date Binary' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "56bf760b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T18:47:35.595059Z",
     "start_time": "2024-10-31T18:47:35.583361Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "import time\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "def evaluate_features(df, num, categ, \n",
    "                      rfe_features, rfe_model, k=5):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    X, y = df.drop(columns=['Claim Injury Type']), df['Claim Injury Type']\n",
    "    kf = KFold(n_splits=k)\n",
    "    selected_features = []\n",
    "\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        \n",
    "        print(f'------------ FOLD ------------ \\n')\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # train & val\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        # Construct the Pipeline \n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "        ('imputer', FunctionTransformer(partial(custom_impute, target='Average Weekly Wage'), validate=False)),  # Corrected line\n",
    "        ('log_transform', FunctionTransformer(log_transform, validate=False)),  \n",
    "        ])\n",
    "        \n",
    "        print(X_train.isna().sum())\n",
    "        \n",
    "        song.play_('audio.mp3')\n",
    "        \n",
    "        # Fit the pipeline on the training data\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Numerical\n",
    "        print('----LASSO----')\n",
    "        lasso = fs.lasso(X_train, y_train, num)\n",
    "        print('----RFE----')\n",
    "        # for model in rfe_model: ## FUTURE\n",
    "        rfe = fs.rfe(X_train, y_train, num, rfe_features, rfe_model)\n",
    "        print('----CORR----')\n",
    "        corr = fs.correlation_matrix(X_train, num)\n",
    "        #print('----VAR----')\n",
    "        var = fs.var(X_train, num)\n",
    "        \n",
    "        # Categorical\n",
    "        print('----CHI2----')\n",
    "        chi2 = fs.chi_squared(X_train, y_train, categ)\n",
    "        print('----MI----')\n",
    "        mutual_information = fs.mutual_information(X_train, y_train, categ)\n",
    "        \n",
    "        \n",
    "        # Combine selected features from each method\n",
    "        num_selected = set(lasso).union(rfe, corr, var)\n",
    "        categ_selected = set(chi2).union(mutual_information)\n",
    "\n",
    "        # Filter training and validation sets based on selected features\n",
    "        num_selected = [feature for feature in num_selected if isinstance(feature, str)]\n",
    "        \n",
    "        #num_selected = num_selected.to_list()\n",
    "        categ_selected = list(categ_selected)\n",
    "        \n",
    "        X_train_selected = X_train[num_selected + categ_selected]\n",
    "        X_val_selected = X_val[num_selected + categ_selected]\n",
    "        \n",
    "        \n",
    "        # Train model and record performance\n",
    "        model = LogisticRegression()\n",
    "        model.fit(X_train_selected, y_train)\n",
    "        y_pred = model.predict(X_val_selected)\n",
    "        \n",
    "        # Print classification report for current fold\n",
    "        print('CLASSIFICATION REPORT \\n')\n",
    "        print(classification_report(y_val, y_pred))\n",
    "\n",
    "        # Save selected features for counting occurrences\n",
    "        selected_features.append(num_selected + categ_selected)\n",
    "\n",
    "        # End timing\n",
    "        end_time1 = time.time()\n",
    "        elapsed_time1 = end_time1 - start_time\n",
    "        print(elapsed_time1)\n",
    "    \n",
    "    # Count occurrences of each feature across folds\n",
    "    feature_counts = Counter(np.concatenate(selected_features))\n",
    "    \n",
    "    song.play_('audio.mp3')\n",
    "    # End timing\n",
    "    end_time2 = time.time()\n",
    "    elapsed_time2 = end_time2 - start_time\n",
    "    print(elapsed_time2)\n",
    "    \n",
    "    # Select only features that appear in all folds\n",
    "    final_features = [feature for feature, count in feature_counts.items() if count == k]\n",
    "    return final_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c31f14e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T18:47:47.835574Z",
     "start_time": "2024-10-31T18:47:35.975912Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ FOLD ------------ \n",
      "\n",
      "Age at Injury                         0\n",
      "Alternative Dispute Resolution        0\n",
      "Attorney/Representative               0\n",
      "Average Weekly Wage               14255\n",
      "Birth Year                        14536\n",
      "Carrier Name                          0\n",
      "Carrier Type                          0\n",
      "County of Injury                      0\n",
      "COVID-19 Indicator                    0\n",
      "District Name                         0\n",
      "Gender                                0\n",
      "IME-4 Count                           0\n",
      "Industry Code                      4482\n",
      "Medical Fee Region                    0\n",
      "WCIO Cause of Injury Code          7178\n",
      "WCIO Nature of Injury Code         7191\n",
      "WCIO Part Of Body Code             7809\n",
      "Zip Code                          14559\n",
      "Number of Dependents                  0\n",
      "Accident Year                      1594\n",
      "Accident Month                     1594\n",
      "Accident Day                       1594\n",
      "Assembly Year                         0\n",
      "Assembly Month                        0\n",
      "Assembly Day                          0\n",
      "C-2 Year                           6601\n",
      "C-2 Month                          6601\n",
      "C-2 Day                            6601\n",
      "C-3 Date Binary                       0\n",
      "First Hearing Year                    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/mm/fxsq_1490x9dd2w76tqvt3kr0000gn/T/tmpgoy2omta.wav':\n",
      "  Duration: 00:00:10.00, bitrate: 1536 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, 2 channels, s16, 1536 kb/s\n",
      "   9.93 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nNearestNeighbors does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m rfe_features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m12\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m \u001b[43mevaluate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcateg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mrfe_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrfe_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mrfe_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mRandomForestClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[77], line 39\u001b[0m, in \u001b[0;36mevaluate_features\u001b[0;34m(df, num, categ, rfe_features, rfe_model, k)\u001b[0m\n\u001b[1;32m     36\u001b[0m song\u001b[38;5;241m.\u001b[39mplay_(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio.mp3\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Fit the pipeline on the training data\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Numerical\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m----LASSO----\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/Text_Mining/lib/python3.10/site-packages/sklearn/pipeline.py:401\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \n\u001b[1;32m    377\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    400\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m--> 401\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/Text_Mining/lib/python3.10/site-packages/sklearn/pipeline.py:359\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    357\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[1;32m    358\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 359\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m~/anaconda3/envs/Text_Mining/lib/python3.10/site-packages/joblib/memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Text_Mining/lib/python3.10/site-packages/sklearn/pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    892\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 893\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    895\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/anaconda3/envs/Text_Mining/lib/python3.10/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/Text_Mining/lib/python3.10/site-packages/sklearn/base.py:881\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m--> 881\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Text_Mining/lib/python3.10/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/Text_Mining/lib/python3.10/site-packages/sklearn/preprocessing/_function_transformer.py:238\u001b[0m, in \u001b[0;36mFunctionTransformer.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform X using the forward function.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;124;03m    Transformed input.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    237\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_input(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkw_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkw_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Text_Mining/lib/python3.10/site-packages/sklearn/preprocessing/_function_transformer.py:310\u001b[0m, in \u001b[0;36mFunctionTransformer._transform\u001b[0;34m(self, X, func, kw_args)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    308\u001b[0m     func \u001b[38;5;241m=\u001b[39m _identity\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkw_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkw_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[65], line 55\u001b[0m, in \u001b[0;36mcustom_impute\u001b[0;34m(df, target)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Wage\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m var_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage Weekly Wage\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 55\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mball_tree_impute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# for all 'code' variables    \u001b[39;00m\n\u001b[1;32m     59\u001b[0m code_columns \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mfilter(regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCode$\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcolumns\n",
      "Cell \u001b[0;32mIn[65], line 16\u001b[0m, in \u001b[0;36mball_tree_impute\u001b[0;34m(df, target, n_neighbors)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Build a ball tree using all features except the target column\u001b[39;00m\n\u001b[1;32m     15\u001b[0m knn \u001b[38;5;241m=\u001b[39m NearestNeighbors(n_neighbors\u001b[38;5;241m=\u001b[39mn_neighbors, algorithm\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mball_tree\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mknn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnon_missing_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Find nearest neighbors for rows with missing values\u001b[39;00m\n\u001b[1;32m     19\u001b[0m _, indices \u001b[38;5;241m=\u001b[39m knn\u001b[38;5;241m.\u001b[39mkneighbors(missing_data[features])\n",
      "File \u001b[0;32m~/anaconda3/envs/Text_Mining/lib/python3.10/site-packages/sklearn/neighbors/_unsupervised.py:176\u001b[0m, in \u001b[0;36mNearestNeighbors.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the nearest neighbors estimator from the training dataset.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \n\u001b[1;32m    161\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03m    The fitted nearest neighbors estimator.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Text_Mining/lib/python3.10/site-packages/sklearn/neighbors/_base.py:491\u001b[0m, in \u001b[0;36mNeighborsBase._fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, (KDTree, BallTree, NeighborsBase)):\n\u001b[0;32m--> 491\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_algorithm_metric()\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/Text_Mining/lib/python3.10/site-packages/sklearn/base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 565\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/anaconda3/envs/Text_Mining/lib/python3.10/site-packages/sklearn/utils/validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    918\u001b[0m         )\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 921\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/anaconda3/envs/Text_Mining/lib/python3.10/site-packages/sklearn/utils/validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nNearestNeighbors does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "rfe_features = [12]\n",
    "\n",
    "evaluate_features(df, num, categ, \n",
    "                  rfe_features = rfe_features,\n",
    "                  rfe_model = RandomForestClassifier(),\n",
    "                  k = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "41f71881",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T19:13:00.627235Z",
     "start_time": "2024-10-31T19:13:00.614419Z"
    }
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'if' statement on line 54 (2429252863.py, line 60)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[158], line 60\u001b[0;36m\u001b[0m\n\u001b[0;31m    code_columns = df.filter(regex='Code$', axis=0).columns\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'if' statement on line 54\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4d30efa",
   "metadata": {},
   "source": [
    "RFE n está a selecionar nenhum número de features (por enquanto), está apenas a mostrar o classification report para cada número de features inputed.\n",
    "\n",
    "__*5 fold train: LogReg, rfe: LogReg, features=[12,13,14,15]*__\n",
    "\n",
    "['Accident Year',\n",
    " 'Number of Dependents',\n",
    " 'C-2 Day',\n",
    " 'Assembly Day',\n",
    " 'First Hearing Year',\n",
    " 'C-2 Month',\n",
    " 'IME-4 Count',\n",
    " 'Assembly Year',\n",
    " 'Age at Injury',\n",
    " 'Birth Year',\n",
    " 'Accident Month',\n",
    " 'Average Weekly Wage',\n",
    " 'Accident Day',\n",
    " 'Assembly Month',\n",
    " 'C-2 Year',\n",
    " 'County of Injury',\n",
    " 'Carrier Name',\n",
    " 'C-3 Date Binary',\n",
    " 'Carrier Type',\n",
    " 'District Name',\n",
    " 'Zip Code',\n",
    " 'Alternative Dispute Resolution',\n",
    " 'Industry Code',\n",
    " 'Gender',\n",
    " 'Attorney/Representative',\n",
    " 'WCIO Nature of Injury Code',\n",
    " 'WCIO Part Of Body Code',\n",
    " 'WCIO Cause of Injury Code',\n",
    " 'COVID-19 Indicator',\n",
    " 'Medical Fee Region']\n",
    " \n",
    "  TIME: \n",
    " \n",
    " __*5 fold train: LogReg, rfe: RF, features=[12]*__\n",
    " \n",
    " ['Assembly Day',\n",
    " 'Assembly Month',\n",
    " 'Assembly Year',\n",
    " 'First Hearing Year',\n",
    " 'Age at Injury',\n",
    " 'C-2 Month',\n",
    " 'Birth Year',\n",
    " 'Accident Month',\n",
    " 'Average Weekly Wage',\n",
    " 'Accident Year',\n",
    " 'IME-4 Count',\n",
    " 'Number of Dependents',\n",
    " 'Accident Day',\n",
    " 'C-2 Day',\n",
    " 'C-2 Year',\n",
    " 'County of Injury',\n",
    " 'Carrier Name',\n",
    " 'C-3 Date Binary',\n",
    " 'Carrier Type',\n",
    " 'District Name',\n",
    " 'Zip Code',\n",
    " 'Alternative Dispute Resolution',\n",
    " 'Industry Code',\n",
    " 'Gender',\n",
    " 'Attorney/Representative',\n",
    " 'WCIO Nature of Injury Code',\n",
    " 'WCIO Part Of Body Code',\n",
    " 'WCIO Cause of Injury Code',\n",
    " 'COVID-19 Indicator',\n",
    " 'Medical Fee Region']\n",
    " \n",
    " TIME: 28min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "39b37222",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T19:09:47.582403Z",
     "start_time": "2024-10-31T19:09:22.854826Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age at Injury                     0\n",
       "Alternative Dispute Resolution    0\n",
       "Attorney/Representative           0\n",
       "Average Weekly Wage               0\n",
       "Birth Year                        0\n",
       "Carrier Name                      0\n",
       "Carrier Type                      0\n",
       "Claim Injury Type                 0\n",
       "County of Injury                  0\n",
       "COVID-19 Indicator                0\n",
       "District Name                     0\n",
       "Gender                            0\n",
       "IME-4 Count                       0\n",
       "Industry Code                     0\n",
       "Medical Fee Region                0\n",
       "WCIO Cause of Injury Code         0\n",
       "WCIO Nature of Injury Code        0\n",
       "WCIO Part Of Body Code            0\n",
       "Zip Code                          0\n",
       "Number of Dependents              0\n",
       "Accident Year                     0\n",
       "Accident Month                    0\n",
       "Accident Day                      0\n",
       "Assembly Year                     0\n",
       "Assembly Month                    0\n",
       "Assembly Day                      0\n",
       "C-2 Year                          0\n",
       "C-2 Month                         0\n",
       "C-2 Day                           0\n",
       "C-3 Date Binary                   0\n",
       "First Hearing Year                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for var_name in df.columns:\n",
    "    if any(word in var_name for word in ['Year', 'Month', 'Day']) and var_name != 'Birth Year':\n",
    "            df[var_name] = df[var_name].fillna(df[var_name].median())\n",
    "\n",
    "    if var_name == 'Birth Year':\n",
    "        # Only perform imputation for rows where both columns are not NaN and Birth Year is NaN or 0\n",
    "            mask = df['Accident Year'].notna() & df['Age at Injury'].notna()\n",
    "            df.loc[mask & (df[var_name].isna() | (df[var_name] == 0)), \n",
    "                    var_name] = df['Accident Year'] - df['Age at Injury']\n",
    "\n",
    "            remaining_nans = df[var_name].isna().sum().sum()\n",
    "            if remaining_nans > 0:\n",
    "                median = df[var_name].median()\n",
    "                df[var_name] = df[var_name].fillna(median)\n",
    "\n",
    "    # Zip Code\n",
    "    if var_name == 'Zip Code':\n",
    "        df[var_name] = df[var_name].fillna(99999)\n",
    "\n",
    "    # Wage\n",
    "    if var_name == 'Average Weekly Wage':\n",
    "        df[var_name] = df[var_name].fillna(0)\n",
    "        #df = ball_tree_impute(df, var_name)\n",
    "\n",
    "\n",
    "    # for all 'code' variables    \n",
    "    code_columns = df.filter(regex='Code$', axis=0).columns\n",
    "    df[code_columns] = df[code_columns].fillna(0)\n",
    "    \n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8d7bbfa5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T19:10:49.072262Z",
     "start_time": "2024-10-31T19:10:48.412442Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nNearestNeighbors does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[146], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mball_tree_impute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAverage Weekly Wage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[143], line 16\u001b[0m, in \u001b[0;36mball_tree_impute\u001b[0;34m(df, target, n_neighbors)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Build a ball tree using all features except the target column\u001b[39;00m\n\u001b[1;32m     15\u001b[0m knn \u001b[38;5;241m=\u001b[39m NearestNeighbors(n_neighbors\u001b[38;5;241m=\u001b[39mn_neighbors, algorithm\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mball_tree\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mknn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnon_missing_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Find nearest neighbors for rows with missing values\u001b[39;00m\n\u001b[1;32m     19\u001b[0m _, indices \u001b[38;5;241m=\u001b[39m knn\u001b[38;5;241m.\u001b[39mkneighbors(missing_data[features])\n",
      "File \u001b[0;32m~/anaconda3/envs/Text_Mining/lib/python3.10/site-packages/sklearn/neighbors/_unsupervised.py:176\u001b[0m, in \u001b[0;36mNearestNeighbors.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the nearest neighbors estimator from the training dataset.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \n\u001b[1;32m    161\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03m    The fitted nearest neighbors estimator.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Text_Mining/lib/python3.10/site-packages/sklearn/neighbors/_base.py:491\u001b[0m, in \u001b[0;36mNeighborsBase._fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, (KDTree, BallTree, NeighborsBase)):\n\u001b[0;32m--> 491\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_algorithm_metric()\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/Text_Mining/lib/python3.10/site-packages/sklearn/base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 565\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/anaconda3/envs/Text_Mining/lib/python3.10/site-packages/sklearn/utils/validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    918\u001b[0m         )\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 921\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/anaconda3/envs/Text_Mining/lib/python3.10/site-packages/sklearn/utils/validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nNearestNeighbors does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "ball_tree_impute(df, 'Average Weekly Wage')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b38cb75",
   "metadata": {},
   "source": [
    "Numerical Features: Lasso, RFE, Variance Threshold, Correlation Matrix, Statistical Tests. <br> <BR>\n",
    "Categorical Features: Chi-Squared Test, Information Gain, Tree-based Methods, Mutual Information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f1106e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
