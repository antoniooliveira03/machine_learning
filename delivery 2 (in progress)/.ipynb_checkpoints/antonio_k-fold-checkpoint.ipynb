{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Machine Learning Project Code</center>\n",
    "\n",
    "<a class=\"anchor\" id=\"top\"></a>\n",
    "\n",
    "## <center>*03 - K-Fold*</center>\n",
    "\n",
    "** **\n",
    "\n",
    "\n",
    "\n",
    "# Table of Contents  <br>\n",
    "\n",
    "\n",
    "1. [Importing Libraries & Data](#1.-Importing-Libraries-&-Data) <br><br>\n",
    "    \n",
    "2. [Cross Validation](#2.-Cross-Validation) <br><br>\n",
    "\n",
    "3. [Final Predictions](#3.-Final-Predictions) <br><br>\n",
    "\n",
    "** **\n",
    "\n",
    "This notebook will consist of the implementation of Stratified K-Fold. It will use the same techniques to fill missing values and treat outliers as Notebook 02. Feature Selection will only be performed in said notebook, and the selected features there will be used here, due to computational complexity and time constraints.\n",
    "\n",
    "Data Scientist Manager: António Oliveira, **20211595**\n",
    "\n",
    "Data Scientist Senior: Tomás Ribeiro, **20240526**\n",
    "\n",
    "Data Scientist Junior: Gonçalo Pacheco, **20240695**\n",
    "\n",
    "Data Analyst Senior: Gonçalo Custódio, **20211643**\n",
    "\n",
    "Data Analyst Junior: Ana Caleiro, **20240696**\n",
    "\n",
    "\n",
    "** ** \n",
    "\n",
    "# 1. Importing Libraries & Data\n",
    "In this section, we set up the foundation for our project by importing the necessary Python libraries and loading the dataset. These libraries provide the tools for data manipulation, visualization, and machine learning modeling throughout the notebook. Additionally, we import the historical claims dataset, which forms the core of our analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T19:38:20.372382Z",
     "start_time": "2024-12-16T19:38:17.786533Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Train-Test Split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Models\n",
    "import models as mod\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import classification_report\n",
    "import metrics as m\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Suppress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T19:38:23.707458Z",
     "start_time": "2024-12-16T19:38:20.375434Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age at Injury</th>\n",
       "      <th>Alternative Dispute Resolution</th>\n",
       "      <th>Attorney/Representative</th>\n",
       "      <th>Average Weekly Wage</th>\n",
       "      <th>Birth Year</th>\n",
       "      <th>C-3 Date</th>\n",
       "      <th>Carrier Name</th>\n",
       "      <th>Carrier Type</th>\n",
       "      <th>Claim Injury Type</th>\n",
       "      <th>County of Injury</th>\n",
       "      <th>COVID-19 Indicator</th>\n",
       "      <th>District Name</th>\n",
       "      <th>First Hearing Date</th>\n",
       "      <th>Gender</th>\n",
       "      <th>IME-4 Count</th>\n",
       "      <th>Industry Code</th>\n",
       "      <th>Medical Fee Region</th>\n",
       "      <th>WCIO Cause of Injury Code</th>\n",
       "      <th>WCIO Nature of Injury Code</th>\n",
       "      <th>WCIO Part Of Body Code</th>\n",
       "      <th>Number of Dependents</th>\n",
       "      <th>Gender Enc</th>\n",
       "      <th>Accident Date Year</th>\n",
       "      <th>Accident Date Month</th>\n",
       "      <th>Accident Date Day</th>\n",
       "      <th>Accident Date Day of Week</th>\n",
       "      <th>Assembly Date Year</th>\n",
       "      <th>Assembly Date Month</th>\n",
       "      <th>Assembly Date Day</th>\n",
       "      <th>Assembly Date Day of Week</th>\n",
       "      <th>C-2 Date Year</th>\n",
       "      <th>C-2 Date Month</th>\n",
       "      <th>C-2 Date Day</th>\n",
       "      <th>C-2 Date Day of Week</th>\n",
       "      <th>Accident to Assembly Time</th>\n",
       "      <th>Assembly to C-2 Time</th>\n",
       "      <th>Accident to C-2 Time</th>\n",
       "      <th>WCIO Codes</th>\n",
       "      <th>Insurance</th>\n",
       "      <th>Zip Code Valid</th>\n",
       "      <th>Industry Sector</th>\n",
       "      <th>Age Group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Claim Identifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5393875</th>\n",
       "      <td>31.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEW HAMPSHIRE INSURANCE CO</td>\n",
       "      <td>1A. PRIVATE</td>\n",
       "      <td>1</td>\n",
       "      <td>ST. LAWRENCE</td>\n",
       "      <td>N</td>\n",
       "      <td>SYRACUSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>I</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>271062</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Retail and Wholesale</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5393091</th>\n",
       "      <td>46.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>1745.93</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>ZURICH AMERICAN INSURANCE CO</td>\n",
       "      <td>1A. PRIVATE</td>\n",
       "      <td>3</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>N</td>\n",
       "      <td>ROCHESTER</td>\n",
       "      <td>2020-02-21</td>\n",
       "      <td>F</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>I</td>\n",
       "      <td>97</td>\n",
       "      <td>49</td>\n",
       "      <td>38</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>974938</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Manufacturing and Construction</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5393889</th>\n",
       "      <td>40.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1434.80</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INDEMNITY INSURANCE CO OF</td>\n",
       "      <td>1A. PRIVATE</td>\n",
       "      <td>3</td>\n",
       "      <td>ORANGE</td>\n",
       "      <td>N</td>\n",
       "      <td>ALBANY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "      <td>II</td>\n",
       "      <td>79</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>79710</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Business Services</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Age at Injury Alternative Dispute Resolution  \\\n",
       "Claim Identifier                                                 \n",
       "5393875                    31.0                              N   \n",
       "5393091                    46.0                              N   \n",
       "5393889                    40.0                              N   \n",
       "\n",
       "                 Attorney/Representative  Average Weekly Wage  Birth Year  \\\n",
       "Claim Identifier                                                            \n",
       "5393875                                N                 0.00      1988.0   \n",
       "5393091                                Y              1745.93      1973.0   \n",
       "5393889                                N              1434.80      1979.0   \n",
       "\n",
       "                    C-3 Date                  Carrier Name Carrier Type  \\\n",
       "Claim Identifier                                                          \n",
       "5393875                  NaN    NEW HAMPSHIRE INSURANCE CO  1A. PRIVATE   \n",
       "5393091           2020-01-14  ZURICH AMERICAN INSURANCE CO  1A. PRIVATE   \n",
       "5393889                  NaN     INDEMNITY INSURANCE CO OF  1A. PRIVATE   \n",
       "\n",
       "                  Claim Injury Type County of Injury COVID-19 Indicator  \\\n",
       "Claim Identifier                                                          \n",
       "5393875                           1     ST. LAWRENCE                  N   \n",
       "5393091                           3          WYOMING                  N   \n",
       "5393889                           3           ORANGE                  N   \n",
       "\n",
       "                 District Name First Hearing Date Gender  IME-4 Count  \\\n",
       "Claim Identifier                                                        \n",
       "5393875               SYRACUSE                NaN      M          NaN   \n",
       "5393091              ROCHESTER         2020-02-21      F          4.0   \n",
       "5393889                 ALBANY                NaN      M          NaN   \n",
       "\n",
       "                  Industry Code Medical Fee Region  WCIO Cause of Injury Code  \\\n",
       "Claim Identifier                                                                \n",
       "5393875                    44.0                  I                         27   \n",
       "5393091                    23.0                  I                         97   \n",
       "5393889                    56.0                 II                         79   \n",
       "\n",
       "                  WCIO Nature of Injury Code  WCIO Part Of Body Code  \\\n",
       "Claim Identifier                                                       \n",
       "5393875                                   10                      62   \n",
       "5393091                                   49                      38   \n",
       "5393889                                    7                      10   \n",
       "\n",
       "                  Number of Dependents  Gender Enc  Accident Date Year  \\\n",
       "Claim Identifier                                                         \n",
       "5393875                            1.0           0              2019.0   \n",
       "5393091                            4.0           1              2019.0   \n",
       "5393889                            6.0           0              2019.0   \n",
       "\n",
       "                  Accident Date Month  Accident Date Day  \\\n",
       "Claim Identifier                                           \n",
       "5393875                          12.0               30.0   \n",
       "5393091                           8.0               30.0   \n",
       "5393889                          12.0                6.0   \n",
       "\n",
       "                  Accident Date Day of Week  Assembly Date Year  \\\n",
       "Claim Identifier                                                  \n",
       "5393875                                 0.0                2020   \n",
       "5393091                                 4.0                2020   \n",
       "5393889                                 4.0                2020   \n",
       "\n",
       "                  Assembly Date Month  Assembly Date Day  \\\n",
       "Claim Identifier                                           \n",
       "5393875                             1                  1   \n",
       "5393091                             1                  1   \n",
       "5393889                             1                  1   \n",
       "\n",
       "                  Assembly Date Day of Week  C-2 Date Year  C-2 Date Month  \\\n",
       "Claim Identifier                                                             \n",
       "5393875                                   2         2019.0            12.0   \n",
       "5393091                                   2         2020.0             1.0   \n",
       "5393889                                   2         2020.0             1.0   \n",
       "\n",
       "                  C-2 Date Day  C-2 Date Day of Week  \\\n",
       "Claim Identifier                                       \n",
       "5393875                   31.0                   1.0   \n",
       "5393091                    1.0                   2.0   \n",
       "5393889                    1.0                   2.0   \n",
       "\n",
       "                  Accident to Assembly Time  Assembly to C-2 Time  \\\n",
       "Claim Identifier                                                    \n",
       "5393875                                 2.0                   1.0   \n",
       "5393091                               124.0                   0.0   \n",
       "5393889                                26.0                   0.0   \n",
       "\n",
       "                  Accident to C-2 Time  WCIO Codes  Insurance  Zip Code Valid  \\\n",
       "Claim Identifier                                                                \n",
       "5393875                            1.0      271062          1               0   \n",
       "5393091                          124.0      974938          1               0   \n",
       "5393889                           26.0       79710          1               0   \n",
       "\n",
       "                                 Industry Sector  Age Group  \n",
       "Claim Identifier                                             \n",
       "5393875                     Retail and Wholesale          1  \n",
       "5393091           Manufacturing and Construction          1  \n",
       "5393889                        Business Services          1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training data\n",
    "df = pd.read_csv('./data/train_data_EDA.csv', index_col = 'Claim Identifier')\n",
    "\n",
    "# Load testing data\n",
    "test1 = pd.read_csv('./data/test_data_EDA.csv', index_col = 'Claim Identifier')\n",
    "\n",
    "# Display the first 3 rows of the training data\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Cross Validation\n",
    "\n",
    "<a href=\"#top\">Top &#129033;</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T19:38:23.830131Z",
     "start_time": "2024-12-16T19:38:23.708920Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the DataFrame into features (X) and target variable (y)\n",
    "X = df.drop('Claim Injury Type', axis=1) \n",
    "y = df['Claim Injury Type']  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stratified K-Fold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T19:38:23.835295Z",
     "start_time": "2024-12-16T19:38:23.832757Z"
    }
   },
   "outputs": [],
   "source": [
    "method = StratifiedKFold(n_splits=15, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T21:18:40.253190Z",
     "start_time": "2024-12-16T19:38:24.874614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Fold took 1.39 minutes\n",
      "This Fold took 1.34 minutes\n",
      "This Fold took 1.34 minutes\n",
      "This Fold took 1.44 minutes\n",
      "This Fold took 1.51 minutes\n",
      "This Fold took 1.52 minutes\n",
      "This Fold took 1.59 minutes\n",
      "This Fold took 1.59 minutes\n",
      "This Fold took 1.38 minutes\n",
      "This Fold took 1.37 minutes\n",
      "This Fold took 1.43 minutes\n",
      "This Fold took 1.36 minutes\n",
      "This Fold took 1.35 minutes\n",
      "This Fold took 1.38 minutes\n",
      "This Fold took 1.39 minutes\n",
      "This Fold took 1.46 minutes\n",
      "This Fold took 1.38 minutes\n",
      "This Fold took 1.35 minutes\n",
      "This Fold took 1.42 minutes\n",
      "This Fold took 1.58 minutes\n",
      "This Fold took 1.4 minutes\n",
      "This Fold took 1.42 minutes\n",
      "This Fold took 1.41 minutes\n",
      "This Fold took 1.39 minutes\n",
      "This Fold took 1.41 minutes\n",
      "This Fold took 1.42 minutes\n",
      "This Fold took 1.41 minutes\n",
      "This Fold took 1.41 minutes\n",
      "This Fold took 1.4 minutes\n",
      "This Fold took 1.41 minutes\n",
      "This Fold took 1.41 minutes\n",
      "This Fold took 1.35 minutes\n",
      "This Fold took 1.37 minutes\n",
      "This Fold took 1.36 minutes\n",
      "This Fold took 4.14 minutes\n",
      "This Fold took 19.46 minutes\n",
      "This Fold took 6.51 minutes\n",
      "This Fold took 6.56 minutes\n",
      "This Fold took 6.22 minutes\n",
      "This Fold took 6.58 minutes\n"
     ]
    }
   ],
   "source": [
    "XGB_freq_no_out_15f = mod.k_fold(method, X, y, test1, 'XGB', params = {},\n",
    "                              enc = 'freq', outliers = True,\n",
    "                              file_name = 'XGB_freq_no_out_15f')\n",
    "\n",
    "XGB_freq_out_15f = mod.k_fold(method, X, y, test1, 'XGB', params = {},\n",
    "                              enc = 'freq', outliers = False,\n",
    "                              file_name = 'XGB_freq_out_15f')\n",
    "\n",
    "XGB_count_no_out_15f = mod.k_fold(method, X, y, test1, 'XGB', params = {},\n",
    "                              enc = 'count', outliers = True,\n",
    "                              file_name = 'XGB_count_no_out_15f')\n",
    "\n",
    "XGB_count_out_15f = mod.k_fold(method, X, y, test1, 'XGB', params = {},\n",
    "                              enc = 'count', outliers = False,\n",
    "                              file_name = 'XGB_count_out_15f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T13:43:29.583346Z",
     "start_time": "2024-12-16T12:38:30.115941Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Fold took 3.38 minutes\n",
      "This Fold took 3.45 minutes\n",
      "This Fold took 3.43 minutes\n",
      "This Fold took 3.39 minutes\n",
      "This Fold took 3.36 minutes\n",
      "This Fold took 3.19 minutes\n",
      "This Fold took 3.2 minutes\n",
      "This Fold took 3.18 minutes\n",
      "This Fold took 3.22 minutes\n",
      "This Fold took 3.27 minutes\n",
      "This Fold took 3.14 minutes\n",
      "This Fold took 3.17 minutes\n",
      "This Fold took 3.2 minutes\n",
      "This Fold took 3.19 minutes\n",
      "This Fold took 3.2 minutes\n",
      "This Fold took 2.97 minutes\n",
      "This Fold took 3.0 minutes\n",
      "This Fold took 3.01 minutes\n",
      "This Fold took 3.06 minutes\n",
      "This Fold took 3.05 minutes\n"
     ]
    }
   ],
   "source": [
    "RF_freq_no_out_15f = mod.k_fold(method, X, y, test1, 'RF', params = {},\n",
    "                              enc = 'freq', outliers = True,\n",
    "                              file_name = 'RF_freq_no_out_15f')\n",
    "\n",
    "RF_freq_out_15f = mod.k_fold(method, X, y, test1, 'RF', params = {},\n",
    "                              enc = 'freq', outliers = False,\n",
    "                              file_name = 'RF_freq_out_15f')\n",
    "\n",
    "RF_count_no_out_15f = mod.k_fold(method, X, y, test1, 'RF', params = {},\n",
    "                              enc = 'count', outliers = True,\n",
    "                              file_name = 'RF_count_no_out_15f')\n",
    "\n",
    "RF_count_out_15f = mod.k_fold(method, X, y, test1, 'RF', params = {},\n",
    "                              enc = 'count', outliers = False,\n",
    "                              file_name = 'RF_count_out_15f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T14:13:32.424561Z",
     "start_time": "2024-12-16T13:46:05.575443Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030632 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2763\n",
      "[LightGBM] [Info] Number of data points in the train set: 454727, number of used features: 50\n",
      "[LightGBM] [Info] Start training from score -3.874529\n",
      "[LightGBM] [Info] Start training from score -0.676691\n",
      "[LightGBM] [Info] Start training from score -2.114330\n",
      "[LightGBM] [Info] Start training from score -1.357652\n",
      "[LightGBM] [Info] Start training from score -2.469974\n",
      "[LightGBM] [Info] Start training from score -4.908650\n",
      "[LightGBM] [Info] Start training from score -8.683647\n",
      "[LightGBM] [Info] Start training from score -7.103197\n",
      "This Fold took 1.52 minutes\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 454694, number of used features: 50\n",
      "[LightGBM] [Info] Start training from score -3.877002\n",
      "[LightGBM] [Info] Start training from score -0.676618\n",
      "[LightGBM] [Info] Start training from score -2.114330\n",
      "[LightGBM] [Info] Start training from score -1.357656\n",
      "[LightGBM] [Info] Start training from score -2.469772\n",
      "[LightGBM] [Info] Start training from score -4.908875\n",
      "[LightGBM] [Info] Start training from score -8.683575\n",
      "[LightGBM] [Info] Start training from score -7.103124\n",
      "This Fold took 1.51 minutes\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032989 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2757\n",
      "[LightGBM] [Info] Number of data points in the train set: 454714, number of used features: 50\n",
      "[LightGBM] [Info] Start training from score -3.876515\n",
      "[LightGBM] [Info] Start training from score -0.676572\n",
      "[LightGBM] [Info] Start training from score -2.114520\n",
      "[LightGBM] [Info] Start training from score -1.357777\n",
      "[LightGBM] [Info] Start training from score -2.469686\n",
      "[LightGBM] [Info] Start training from score -4.907728\n",
      "[LightGBM] [Info] Start training from score -8.670715\n",
      "[LightGBM] [Info] Start training from score -7.100498\n",
      "This Fold took 1.52 minutes\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032879 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2757\n",
      "[LightGBM] [Info] Number of data points in the train set: 454704, number of used features: 50\n",
      "[LightGBM] [Info] Start training from score -3.876387\n",
      "[LightGBM] [Info] Start training from score -0.676623\n",
      "[LightGBM] [Info] Start training from score -2.114807\n",
      "[LightGBM] [Info] Start training from score -1.357387\n",
      "[LightGBM] [Info] Start training from score -2.470080\n",
      "[LightGBM] [Info] Start training from score -4.908301\n",
      "[LightGBM] [Info] Start training from score -8.696669\n",
      "[LightGBM] [Info] Start training from score -7.100476\n",
      "This Fold took 1.45 minutes\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032506 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2761\n",
      "[LightGBM] [Info] Number of data points in the train set: 454757, number of used features: 50\n",
      "[LightGBM] [Info] Start training from score -3.875973\n",
      "[LightGBM] [Info] Start training from score -0.676692\n",
      "[LightGBM] [Info] Start training from score -2.114669\n",
      "[LightGBM] [Info] Start training from score -1.357299\n",
      "[LightGBM] [Info] Start training from score -2.470170\n",
      "[LightGBM] [Info] Start training from score -4.908715\n",
      "[LightGBM] [Info] Start training from score -8.696785\n",
      "[LightGBM] [Info] Start training from score -7.103263\n",
      "This Fold took 1.43 minutes\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038884 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2528\n",
      "[LightGBM] [Info] Number of data points in the train set: 459220, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -3.828846\n",
      "[LightGBM] [Info] Start training from score -0.679083\n",
      "[LightGBM] [Info] Start training from score -2.119944\n",
      "[LightGBM] [Info] Start training from score -1.352037\n",
      "[LightGBM] [Info] Start training from score -2.475656\n",
      "[LightGBM] [Info] Start training from score -4.914913\n",
      "[LightGBM] [Info] Start training from score -8.680576\n",
      "[LightGBM] [Info] Start training from score -7.107696\n",
      "This Fold took 1.44 minutes\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2531\n",
      "[LightGBM] [Info] Number of data points in the train set: 459220, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -3.828846\n",
      "[LightGBM] [Info] Start training from score -0.679083\n",
      "[LightGBM] [Info] Start training from score -2.119926\n",
      "[LightGBM] [Info] Start training from score -1.352037\n",
      "[LightGBM] [Info] Start training from score -2.475656\n",
      "[LightGBM] [Info] Start training from score -4.915210\n",
      "[LightGBM] [Info] Start training from score -8.680576\n",
      "[LightGBM] [Info] Start training from score -7.107696\n",
      "This Fold took 1.45 minutes\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031774 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2524\n",
      "[LightGBM] [Info] Number of data points in the train set: 459220, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -3.828946\n",
      "[LightGBM] [Info] Start training from score -0.679083\n",
      "[LightGBM] [Info] Start training from score -2.119926\n",
      "[LightGBM] [Info] Start training from score -1.352037\n",
      "[LightGBM] [Info] Start training from score -2.475656\n",
      "[LightGBM] [Info] Start training from score -4.914913\n",
      "[LightGBM] [Info] Start training from score -8.680576\n",
      "[LightGBM] [Info] Start training from score -7.107696\n",
      "This Fold took 1.45 minutes\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037544 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2531\n",
      "[LightGBM] [Info] Number of data points in the train set: 459220, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -3.828846\n",
      "[LightGBM] [Info] Start training from score -0.679079\n",
      "[LightGBM] [Info] Start training from score -2.119926\n",
      "[LightGBM] [Info] Start training from score -1.352046\n",
      "[LightGBM] [Info] Start training from score -2.475656\n",
      "[LightGBM] [Info] Start training from score -4.914913\n",
      "[LightGBM] [Info] Start training from score -8.693479\n",
      "[LightGBM] [Info] Start training from score -7.107696\n",
      "This Fold took 1.49 minutes\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030550 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2528\n",
      "[LightGBM] [Info] Number of data points in the train set: 459220, number of used features: 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Start training from score -3.828846\n",
      "[LightGBM] [Info] Start training from score -0.679079\n",
      "[LightGBM] [Info] Start training from score -2.119926\n",
      "[LightGBM] [Info] Start training from score -1.352046\n",
      "[LightGBM] [Info] Start training from score -2.475656\n",
      "[LightGBM] [Info] Start training from score -4.914913\n",
      "[LightGBM] [Info] Start training from score -8.693479\n",
      "[LightGBM] [Info] Start training from score -7.107696\n",
      "This Fold took 1.47 minutes\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2763\n",
      "[LightGBM] [Info] Number of data points in the train set: 454727, number of used features: 50\n",
      "[LightGBM] [Info] Start training from score -3.874529\n",
      "[LightGBM] [Info] Start training from score -0.676691\n",
      "[LightGBM] [Info] Start training from score -2.114330\n",
      "[LightGBM] [Info] Start training from score -1.357652\n",
      "[LightGBM] [Info] Start training from score -2.469974\n",
      "[LightGBM] [Info] Start training from score -4.908650\n",
      "[LightGBM] [Info] Start training from score -8.683647\n",
      "[LightGBM] [Info] Start training from score -7.103197\n",
      "This Fold took 1.26 minutes\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025123 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 454694, number of used features: 50\n",
      "[LightGBM] [Info] Start training from score -3.877002\n",
      "[LightGBM] [Info] Start training from score -0.676618\n",
      "[LightGBM] [Info] Start training from score -2.114330\n",
      "[LightGBM] [Info] Start training from score -1.357656\n",
      "[LightGBM] [Info] Start training from score -2.469772\n",
      "[LightGBM] [Info] Start training from score -4.908875\n",
      "[LightGBM] [Info] Start training from score -8.683575\n",
      "[LightGBM] [Info] Start training from score -7.103124\n",
      "This Fold took 1.22 minutes\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031486 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2757\n",
      "[LightGBM] [Info] Number of data points in the train set: 454714, number of used features: 50\n",
      "[LightGBM] [Info] Start training from score -3.876515\n",
      "[LightGBM] [Info] Start training from score -0.676572\n",
      "[LightGBM] [Info] Start training from score -2.114520\n",
      "[LightGBM] [Info] Start training from score -1.357777\n",
      "[LightGBM] [Info] Start training from score -2.469686\n",
      "[LightGBM] [Info] Start training from score -4.907728\n",
      "[LightGBM] [Info] Start training from score -8.670715\n",
      "[LightGBM] [Info] Start training from score -7.100498\n",
      "This Fold took 1.22 minutes\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026799 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2757\n",
      "[LightGBM] [Info] Number of data points in the train set: 454704, number of used features: 50\n",
      "[LightGBM] [Info] Start training from score -3.876387\n",
      "[LightGBM] [Info] Start training from score -0.676623\n",
      "[LightGBM] [Info] Start training from score -2.114807\n",
      "[LightGBM] [Info] Start training from score -1.357387\n",
      "[LightGBM] [Info] Start training from score -2.470080\n",
      "[LightGBM] [Info] Start training from score -4.908301\n",
      "[LightGBM] [Info] Start training from score -8.696669\n",
      "[LightGBM] [Info] Start training from score -7.100476\n",
      "This Fold took 1.22 minutes\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031536 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2761\n",
      "[LightGBM] [Info] Number of data points in the train set: 454757, number of used features: 50\n",
      "[LightGBM] [Info] Start training from score -3.875973\n",
      "[LightGBM] [Info] Start training from score -0.676692\n",
      "[LightGBM] [Info] Start training from score -2.114669\n",
      "[LightGBM] [Info] Start training from score -1.357299\n",
      "[LightGBM] [Info] Start training from score -2.470170\n",
      "[LightGBM] [Info] Start training from score -4.908715\n",
      "[LightGBM] [Info] Start training from score -8.696785\n",
      "[LightGBM] [Info] Start training from score -7.103263\n",
      "This Fold took 1.23 minutes\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031861 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2528\n",
      "[LightGBM] [Info] Number of data points in the train set: 459220, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -3.828846\n",
      "[LightGBM] [Info] Start training from score -0.679083\n",
      "[LightGBM] [Info] Start training from score -2.119944\n",
      "[LightGBM] [Info] Start training from score -1.352037\n",
      "[LightGBM] [Info] Start training from score -2.475656\n",
      "[LightGBM] [Info] Start training from score -4.914913\n",
      "[LightGBM] [Info] Start training from score -8.680576\n",
      "[LightGBM] [Info] Start training from score -7.107696\n",
      "This Fold took 1.21 minutes\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033309 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2531\n",
      "[LightGBM] [Info] Number of data points in the train set: 459220, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -3.828846\n",
      "[LightGBM] [Info] Start training from score -0.679083\n",
      "[LightGBM] [Info] Start training from score -2.119926\n",
      "[LightGBM] [Info] Start training from score -1.352037\n",
      "[LightGBM] [Info] Start training from score -2.475656\n",
      "[LightGBM] [Info] Start training from score -4.915210\n",
      "[LightGBM] [Info] Start training from score -8.680576\n",
      "[LightGBM] [Info] Start training from score -7.107696\n",
      "This Fold took 1.21 minutes\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2524\n",
      "[LightGBM] [Info] Number of data points in the train set: 459220, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -3.828946\n",
      "[LightGBM] [Info] Start training from score -0.679083\n",
      "[LightGBM] [Info] Start training from score -2.119926\n",
      "[LightGBM] [Info] Start training from score -1.352037\n",
      "[LightGBM] [Info] Start training from score -2.475656\n",
      "[LightGBM] [Info] Start training from score -4.914913\n",
      "[LightGBM] [Info] Start training from score -8.680576\n",
      "[LightGBM] [Info] Start training from score -7.107696\n",
      "This Fold took 1.21 minutes\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044145 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2531\n",
      "[LightGBM] [Info] Number of data points in the train set: 459220, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -3.828846\n",
      "[LightGBM] [Info] Start training from score -0.679079\n",
      "[LightGBM] [Info] Start training from score -2.119926\n",
      "[LightGBM] [Info] Start training from score -1.352046\n",
      "[LightGBM] [Info] Start training from score -2.475656\n",
      "[LightGBM] [Info] Start training from score -4.914913\n",
      "[LightGBM] [Info] Start training from score -8.693479\n",
      "[LightGBM] [Info] Start training from score -7.107696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Fold took 1.21 minutes\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027036 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2528\n",
      "[LightGBM] [Info] Number of data points in the train set: 459220, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -3.828846\n",
      "[LightGBM] [Info] Start training from score -0.679079\n",
      "[LightGBM] [Info] Start training from score -2.119926\n",
      "[LightGBM] [Info] Start training from score -1.352046\n",
      "[LightGBM] [Info] Start training from score -2.475656\n",
      "[LightGBM] [Info] Start training from score -4.914913\n",
      "[LightGBM] [Info] Start training from score -8.693479\n",
      "[LightGBM] [Info] Start training from score -7.107696\n",
      "This Fold took 1.21 minutes\n"
     ]
    }
   ],
   "source": [
    "LGBM_freq_no_out_15f = mod.k_fold(method, X, y, test1, 'LGBM', params = {},\n",
    "                              enc = 'freq', outliers = True,\n",
    "                              file_name = 'LGBM_freq_no_out_15f')\n",
    "\n",
    "LGBM_freq_out_15f = mod.k_fold(method, X, y, test1, 'LGBM', params = {},\n",
    "                              enc = 'freq', outliers = False,\n",
    "                              file_name = 'LGBM_freq_out_15f')\n",
    "\n",
    "LGBM_count_no_out_15f = mod.k_fold(method, X, y, test1, 'LGBM', params = {},\n",
    "                              enc = 'count', outliers = True,\n",
    "                              file_name = 'LGBM_count_no_out_15f')\n",
    "\n",
    "LGBM_count_out_15f = mod.k_fold(method, X, y, test1, 'LGBM', params = {},\n",
    "                              enc = 'count', outliers = False,\n",
    "                              file_name = 'LGBM_count_out_15f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T21:19:04.344718Z",
     "start_time": "2024-12-16T21:18:40.258947Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/mm/fxsq_1490x9dd2w76tqvt3kr0000gn/T/tmp5_5igg01.wav':\n",
      "  Duration: 00:00:10.00, bitrate: 1536 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, 2 channels, s16, 1536 kb/s\n",
      "SDL_OpenAudio (2 channels, 48000 Hz): CoreAudio error (AudioQueueStart): 35\n",
      "SDL_OpenAudio (1 channels, 48000 Hz): CoreAudio error (AudioQueueStart): 35\n",
      "SDL_OpenAudio (2 channels, 44100 Hz): CoreAudio error (AudioQueueStart): 35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SDL_OpenAudio (1 channels, 44100 Hz): CoreAudio error (AudioQueueStart): 35\n",
      "No more combinations to try, audio open failed\n",
      "Failed to open file '/var/folders/mm/fxsq_1490x9dd2w76tqvt3kr0000gn/T/tmp5_5igg01.wav' or configure filtergraph\n",
      "    nan    :  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    }
   ],
   "source": [
    "import play_song as s\n",
    "s.play_('audio.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:25:01.349434Z",
     "start_time": "2024-12-16T15:25:01.330247Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGB_freq_no_out</th>\n",
       "      <th>XGB_freq_out</th>\n",
       "      <th>XGB_count_no_out</th>\n",
       "      <th>XGB_count_out</th>\n",
       "      <th>XGB_freq_no_out_10f</th>\n",
       "      <th>XGB_freq_out_10f</th>\n",
       "      <th>XGB_count_no_out_10f</th>\n",
       "      <th>XGB_count_out_10f</th>\n",
       "      <th>RF_freq_no_out</th>\n",
       "      <th>RF_freq_out</th>\n",
       "      <th>RF_count_no_out</th>\n",
       "      <th>RF_count_out</th>\n",
       "      <th>LGBM_freq_no_out</th>\n",
       "      <th>LGBM_freq_out</th>\n",
       "      <th>LGBM_count_no_out</th>\n",
       "      <th>LGBM_count_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train F1 macro</th>\n",
       "      <td>0.67+/-0.002</td>\n",
       "      <td>0.67+/-0.001</td>\n",
       "      <td>0.669+/-0.001</td>\n",
       "      <td>0.669+/-0.001</td>\n",
       "      <td>0.67+/-0.002</td>\n",
       "      <td>0.67+/-0.001</td>\n",
       "      <td>0.669+/-0.001</td>\n",
       "      <td>0.669+/-0.001</td>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.422+/-0.015</td>\n",
       "      <td>0.437+/-0.015</td>\n",
       "      <td>0.409+/-0.009</td>\n",
       "      <td>0.419+/-0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation F1 macro</th>\n",
       "      <td>0.449+/-0.006</td>\n",
       "      <td>0.452+/-0.004</td>\n",
       "      <td>0.45+/-0.005</td>\n",
       "      <td>0.452+/-0.003</td>\n",
       "      <td>0.449+/-0.006</td>\n",
       "      <td>0.452+/-0.004</td>\n",
       "      <td>0.45+/-0.005</td>\n",
       "      <td>0.452+/-0.003</td>\n",
       "      <td>0.39+/-0.004</td>\n",
       "      <td>0.393+/-0.006</td>\n",
       "      <td>0.39+/-0.004</td>\n",
       "      <td>0.39+/-0.003</td>\n",
       "      <td>0.391+/-0.007</td>\n",
       "      <td>0.398+/-0.005</td>\n",
       "      <td>0.385+/-0.006</td>\n",
       "      <td>0.392+/-0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision Train</th>\n",
       "      <td>0.837+/-0.002</td>\n",
       "      <td>0.835+/-0.001</td>\n",
       "      <td>0.838+/-0.003</td>\n",
       "      <td>0.835+/-0.003</td>\n",
       "      <td>0.837+/-0.002</td>\n",
       "      <td>0.835+/-0.001</td>\n",
       "      <td>0.838+/-0.003</td>\n",
       "      <td>0.835+/-0.003</td>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.496+/-0.032</td>\n",
       "      <td>0.514+/-0.016</td>\n",
       "      <td>0.485+/-0.025</td>\n",
       "      <td>0.491+/-0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision Validation</th>\n",
       "      <td>0.569+/-0.011</td>\n",
       "      <td>0.571+/-0.003</td>\n",
       "      <td>0.572+/-0.011</td>\n",
       "      <td>0.575+/-0.007</td>\n",
       "      <td>0.569+/-0.011</td>\n",
       "      <td>0.571+/-0.003</td>\n",
       "      <td>0.572+/-0.011</td>\n",
       "      <td>0.575+/-0.007</td>\n",
       "      <td>0.52+/-0.027</td>\n",
       "      <td>0.531+/-0.018</td>\n",
       "      <td>0.524+/-0.027</td>\n",
       "      <td>0.53+/-0.027</td>\n",
       "      <td>0.433+/-0.016</td>\n",
       "      <td>0.444+/-0.01</td>\n",
       "      <td>0.431+/-0.012</td>\n",
       "      <td>0.44+/-0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall Train</th>\n",
       "      <td>0.654+/-0.001</td>\n",
       "      <td>0.654+/-0.001</td>\n",
       "      <td>0.653+/-0.001</td>\n",
       "      <td>0.653+/-0.002</td>\n",
       "      <td>0.654+/-0.001</td>\n",
       "      <td>0.654+/-0.001</td>\n",
       "      <td>0.653+/-0.001</td>\n",
       "      <td>0.653+/-0.002</td>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.421+/-0.017</td>\n",
       "      <td>0.444+/-0.012</td>\n",
       "      <td>0.422+/-0.017</td>\n",
       "      <td>0.435+/-0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall Validation</th>\n",
       "      <td>0.433+/-0.008</td>\n",
       "      <td>0.433+/-0.005</td>\n",
       "      <td>0.433+/-0.007</td>\n",
       "      <td>0.434+/-0.005</td>\n",
       "      <td>0.433+/-0.008</td>\n",
       "      <td>0.433+/-0.005</td>\n",
       "      <td>0.433+/-0.007</td>\n",
       "      <td>0.434+/-0.005</td>\n",
       "      <td>0.377+/-0.002</td>\n",
       "      <td>0.378+/-0.003</td>\n",
       "      <td>0.377+/-0.002</td>\n",
       "      <td>0.376+/-0.002</td>\n",
       "      <td>0.398+/-0.012</td>\n",
       "      <td>0.409+/-0.012</td>\n",
       "      <td>0.395+/-0.012</td>\n",
       "      <td>0.402+/-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>1.22+/-0.028</td>\n",
       "      <td>1.222+/-0.031</td>\n",
       "      <td>1.048+/-0.033</td>\n",
       "      <td>1.232+/-0.123</td>\n",
       "      <td>1.578+/-0.054</td>\n",
       "      <td>1.624+/-0.048</td>\n",
       "      <td>1.388+/-0.038</td>\n",
       "      <td>1.27+/-0.083</td>\n",
       "      <td>3.402+/-0.033</td>\n",
       "      <td>3.212+/-0.032</td>\n",
       "      <td>3.18+/-0.023</td>\n",
       "      <td>3.018+/-0.033</td>\n",
       "      <td>1.486+/-0.038</td>\n",
       "      <td>1.46+/-0.018</td>\n",
       "      <td>1.23+/-0.015</td>\n",
       "      <td>1.21+/-0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     XGB_freq_no_out   XGB_freq_out XGB_count_no_out  \\\n",
       "Train F1 macro          0.67+/-0.002   0.67+/-0.001    0.669+/-0.001   \n",
       "Validation F1 macro    0.449+/-0.006  0.452+/-0.004     0.45+/-0.005   \n",
       "Precision Train        0.837+/-0.002  0.835+/-0.001    0.838+/-0.003   \n",
       "Precision Validation   0.569+/-0.011  0.571+/-0.003    0.572+/-0.011   \n",
       "Recall Train           0.654+/-0.001  0.654+/-0.001    0.653+/-0.001   \n",
       "Recall Validation      0.433+/-0.008  0.433+/-0.005    0.433+/-0.007   \n",
       "Time                    1.22+/-0.028  1.222+/-0.031    1.048+/-0.033   \n",
       "\n",
       "                      XGB_count_out XGB_freq_no_out_10f XGB_freq_out_10f  \\\n",
       "Train F1 macro        0.669+/-0.001        0.67+/-0.002     0.67+/-0.001   \n",
       "Validation F1 macro   0.452+/-0.003       0.449+/-0.006    0.452+/-0.004   \n",
       "Precision Train       0.835+/-0.003       0.837+/-0.002    0.835+/-0.001   \n",
       "Precision Validation  0.575+/-0.007       0.569+/-0.011    0.571+/-0.003   \n",
       "Recall Train          0.653+/-0.002       0.654+/-0.001    0.654+/-0.001   \n",
       "Recall Validation     0.434+/-0.005       0.433+/-0.008    0.433+/-0.005   \n",
       "Time                  1.232+/-0.123       1.578+/-0.054    1.624+/-0.048   \n",
       "\n",
       "                     XGB_count_no_out_10f XGB_count_out_10f RF_freq_no_out  \\\n",
       "Train F1 macro              0.669+/-0.001     0.669+/-0.001      1.0+/-0.0   \n",
       "Validation F1 macro          0.45+/-0.005     0.452+/-0.003   0.39+/-0.004   \n",
       "Precision Train             0.838+/-0.003     0.835+/-0.003      1.0+/-0.0   \n",
       "Precision Validation        0.572+/-0.011     0.575+/-0.007   0.52+/-0.027   \n",
       "Recall Train                0.653+/-0.001     0.653+/-0.002      1.0+/-0.0   \n",
       "Recall Validation           0.433+/-0.007     0.434+/-0.005  0.377+/-0.002   \n",
       "Time                        1.388+/-0.038      1.27+/-0.083  3.402+/-0.033   \n",
       "\n",
       "                        RF_freq_out RF_count_no_out   RF_count_out  \\\n",
       "Train F1 macro            1.0+/-0.0       1.0+/-0.0      1.0+/-0.0   \n",
       "Validation F1 macro   0.393+/-0.006    0.39+/-0.004   0.39+/-0.003   \n",
       "Precision Train           1.0+/-0.0       1.0+/-0.0      1.0+/-0.0   \n",
       "Precision Validation  0.531+/-0.018   0.524+/-0.027   0.53+/-0.027   \n",
       "Recall Train              1.0+/-0.0       1.0+/-0.0      1.0+/-0.0   \n",
       "Recall Validation     0.378+/-0.003   0.377+/-0.002  0.376+/-0.002   \n",
       "Time                  3.212+/-0.032    3.18+/-0.023  3.018+/-0.033   \n",
       "\n",
       "                     LGBM_freq_no_out  LGBM_freq_out LGBM_count_no_out  \\\n",
       "Train F1 macro          0.422+/-0.015  0.437+/-0.015     0.409+/-0.009   \n",
       "Validation F1 macro     0.391+/-0.007  0.398+/-0.005     0.385+/-0.006   \n",
       "Precision Train         0.496+/-0.032  0.514+/-0.016     0.485+/-0.025   \n",
       "Precision Validation    0.433+/-0.016   0.444+/-0.01     0.431+/-0.012   \n",
       "Recall Train            0.421+/-0.017  0.444+/-0.012     0.422+/-0.017   \n",
       "Recall Validation       0.398+/-0.012  0.409+/-0.012     0.395+/-0.012   \n",
       "Time                    1.486+/-0.038   1.46+/-0.018      1.23+/-0.015   \n",
       "\n",
       "                     LGBM_count_out  \n",
       "Train F1 macro        0.419+/-0.008  \n",
       "Validation F1 macro   0.392+/-0.004  \n",
       "Precision Train       0.491+/-0.021  \n",
       "Precision Validation   0.44+/-0.008  \n",
       "Recall Train          0.435+/-0.021  \n",
       "Recall Validation      0.402+/-0.01  \n",
       "Time                     1.21+/-0.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [XGB_freq_no_out_10f, XGB_freq_out_10f, \n",
    "          XGB_count_no_out_10f, XGB_count_out_10f,\n",
    "          RF_freq_no_out, RF_freq_out,\n",
    "          RF_count_no_out, RF_count_out,\n",
    "          LGBM_freq_no_out, LGBM_freq_out,\n",
    "          LGBM_count_no_out, LGBM_count_out]\n",
    "\n",
    "model_names = ['XGB_freq_no_out_10f', 'XGB_freq_out_10f', \n",
    "               'XGB_count_no_out_10f', 'XGB_count_out_10f',\n",
    "               'RF_freq_no_out', 'RF_freq_out',\n",
    "               'RF_count_no_out', 'RF_count_out',\n",
    "               'LGBM_freq_no_out', 'LGBM_freq_out',\n",
    "               'LGBM_count_no_out', 'LGBM_count_out']\n",
    "\n",
    "m.metrics2(models, model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WORK IN PROGRESS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T19:31:08.172092Z",
     "start_time": "2024-12-16T19:31:08.118402Z"
    }
   },
   "outputs": [],
   "source": [
    "# # \n",
    "# import time\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Preprocessing\n",
    "# import utils2 as p\n",
    "\n",
    "# # Scalers\n",
    "# from sklearn.preprocessing import (\n",
    "#     StandardScaler,\n",
    "#     MinMaxScaler,\n",
    "#     RobustScaler)\n",
    "\n",
    "# # Models\n",
    "# from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier, \\\n",
    "#     GradientBoostingClassifier, AdaBoostClassifier\n",
    "# from xgboost import XGBClassifier \n",
    "# from lightgbm import LGBMClassifier\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "# # Metrics\n",
    "# from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "\n",
    "# def run_model(model_name, X, y, params = None):\n",
    "\n",
    "#     if params is None:\n",
    "#         params = {}\n",
    "\n",
    "#     if model_name == 'LR':\n",
    "#         model = LogisticRegression(**params).fit(X, y)\n",
    "#     elif model_name == 'SGD':\n",
    "#         model = SGDClassifier(**params).fit(X, y)\n",
    "#     elif model_name == 'DT':\n",
    "#         model = DecisionTreeClassifier(**params).fit(X, y)\n",
    "#     elif model_name == 'RF':\n",
    "#         model = RandomForestClassifier(**params).fit(X, y)\n",
    "#     elif model_name == 'AdaBoost':\n",
    "#         model = AdaBoostClassifier(**params).fit(X, y)\n",
    "#     elif model_name == 'GBoost':\n",
    "#         model = GradientBoostingClassifier(**params).fit(X, y)\n",
    "#     elif model_name == 'XGB':\n",
    "#         model = XGBClassifier(**params).fit(X, y)\n",
    "#     elif model_name == 'MLP':\n",
    "#         model = MLPClassifier(**params).fit(X, y)\n",
    "#     elif model_name == 'GNB':  \n",
    "#         model = GaussianNB().fit(X, y)\n",
    "#     elif model_name == 'CNB':  \n",
    "#         model = CategoricalNB().fit(X, y)\n",
    "#     elif model_name == 'KNN':  \n",
    "#         model = KNeighborsClassifier(**params).fit(X, y)\n",
    "#     elif model_name == 'LGBM':  \n",
    "#         model = LGBMClassifier(**params).fit(X, y)\n",
    "#     elif model_name == 'SVM':  \n",
    "#         model = SVC(**params).fit(X, y)\n",
    "    \n",
    "#     return model\n",
    "\n",
    "\n",
    "\n",
    "# def custom_predict(probabilities, threshold):\n",
    "#     rare_classes = [5, 6, 7]  \n",
    "#     for rare_class in rare_classes:\n",
    "        \n",
    "#         if probabilities[rare_class] > threshold:\n",
    "#             return rare_class\n",
    "        \n",
    "#     return np.argmax(probabilities)\n",
    "\n",
    "\n",
    "\n",
    "# def k_fold(method, X, y, test1, model_name, \n",
    "#            params, enc, outliers = False,\n",
    "#            file_name = None):\n",
    "\n",
    "#     # Save metrics\n",
    "#     f1macro_train = []\n",
    "#     f1macro_val = []\n",
    "#     precision_train = []\n",
    "#     precision_val = []\n",
    "#     recall_train = []\n",
    "#     recall_val = []\n",
    "#     timer = []\n",
    "    \n",
    "#     # Mapping\n",
    "#     label_mapping = {\n",
    "#         0: \"1. CANCELLED\",\n",
    "#         1: \"2. NON-COMP\",\n",
    "#         2: \"3. MED ONLY\",\n",
    "#         3: \"4. TEMPORARY\",\n",
    "#         4: \"5. PPD SCH LOSS\",\n",
    "#         5: \"6. PPD NSL\",\n",
    "#         6: \"7. PTD\",\n",
    "#         7: \"8. DEATH\"}\n",
    "    \n",
    "#     test_preds = np.zeros((len(test1), len(label_mapping)))\n",
    "\n",
    "\n",
    "#     # For each fold\n",
    "#     for train_index, val_index in method.split(X, y):\n",
    "#         X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "#         y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "#         test = test1.copy()\n",
    "\n",
    "#         start_time = time.time()\n",
    "        \n",
    "#         # ENCODING\n",
    "#         X_train['Alternative Dispute Resolution Bin'] = X_train['Alternative Dispute Resolution'].replace({'N': 0, 'Y': 1, 'U': 1})\n",
    "#         X_val['Alternative Dispute Resolution Bin'] = X_val['Alternative Dispute Resolution'].replace({'N': 0, 'Y': 1, 'U': 1})\n",
    "#         test['Alternative Dispute Resolution Bin'] = test['Alternative Dispute Resolution'].replace({'N': 0, 'Y': 1, 'U': 1})\n",
    "\n",
    "#         X_train['Attorney/Representative Bin'] = X_train['Attorney/Representative'].replace({'N': 0, 'Y': 1})\n",
    "#         X_val['Attorney/Representative Bin'] = X_val['Attorney/Representative'].replace({'N': 0, 'Y': 1})\n",
    "#         test['Attorney/Representative Bin'] = test['Attorney/Representative'].replace({'N': 0, 'Y': 1})\n",
    "\n",
    "#         train_carriers = set(X_train['Carrier Name'].unique())\n",
    "#         test_carriers = set(test['Carrier Name'].unique())\n",
    "#         common_categories = train_carriers.intersection(test_carriers)\n",
    "#         common_category_map = {category: idx + 1 for idx, \n",
    "#                            category in enumerate(common_categories)}\n",
    "\n",
    "#         X_train['Carrier Name Enc'] = X_train['Carrier Name'].map(common_category_map).fillna(0).astype(int)\n",
    "#         X_val['Carrier Name Enc'] = X_val['Carrier Name'].map(common_category_map).fillna(0).astype(int)\n",
    "#         test['Carrier Name Enc'] = test['Carrier Name'].map(common_category_map).fillna(0).astype(int)\n",
    "\n",
    "#         X_train, X_val, test = p.encode(X_train, X_val, test, 'Carrier Name Enc', enc)\n",
    "\n",
    "#         X_train, X_val, test = p.encode(X_train, X_val, test, 'Carrier Type', enc)\n",
    "#         X_train, X_val, test = p.encode(X_train, X_val, test, 'Carrier Type', 'OHE')\n",
    "\n",
    "#         X_train, X_val, test = p.encode(X_train, X_val, test, 'County of Injury', enc)\n",
    "\n",
    "#         X_train['COVID-19 Indicator Enc'] = X_train['COVID-19 Indicator'].replace({'N': 0, 'Y': 1})\n",
    "#         X_val['COVID-19 Indicator Enc'] = X_val['COVID-19 Indicator'].replace({'N': 0, 'Y': 1})\n",
    "#         test['COVID-19 Indicator Enc'] = test['COVID-19 Indicator'].replace({'N': 0, 'Y': 1})\n",
    "\n",
    "#         X_train, X_val, test = p.encode(X_train, X_val, test, 'District Name', enc)\n",
    "\n",
    "#         X_train, X_val, test = p.encode(X_train, X_val, test, 'Gender', 'OHE')\n",
    "\n",
    "#         X_train, X_val, test = p.encode(X_train, X_val, test, 'Medical Fee Region', enc)\n",
    "\n",
    "#         X_train, X_val, test = p.encode(X_train, X_val, test, 'Industry Sector', enc)\n",
    "\n",
    "#         drop = ['Alternative Dispute Resolution', 'Attorney/Representative', 'Carrier Type', 'County of Injury',\n",
    "#                 'COVID-19 Indicator', 'District Name', 'Gender', 'Carrier Name',\n",
    "#                 'Medical Fee Region', 'Industry Sector']\n",
    "\n",
    "#         X_train.drop(columns = drop, axis = 1, inplace = True)\n",
    "#         X_val.drop(columns = drop, axis = 1, inplace = True)\n",
    "#         test.drop(columns = drop, axis = 1, inplace = True)\n",
    "\n",
    "#         # MISSING VALUES\n",
    "#         X_train['C-3 Date Binary'] = X_train['C-3 Date'].notna().astype(int)\n",
    "#         X_val['C-3 Date Binary'] = X_val['C-3 Date'].notna().astype(int)\n",
    "#         test['C-3 Date Binary'] = test['C-3 Date'].notna().astype(int)\n",
    "\n",
    "#         X_train['First Hearing Date Binary'] = X_train['First Hearing Date'].notna().astype(int)\n",
    "#         X_val['First Hearing Date Binary'] = X_val['First Hearing Date'].notna().astype(int)\n",
    "#         test['First Hearing Date Binary'] = test['First Hearing Date'].notna().astype(int)\n",
    "\n",
    "#         drop = ['C-3 Date', 'First Hearing Date']\n",
    "#         X_train.drop(columns = drop, axis = 1, inplace = True)\n",
    "#         X_val.drop(columns = drop, axis = 1, inplace = True)\n",
    "#         test.drop(columns = drop, axis = 1, inplace = True)\n",
    "\n",
    "#         X_train['IME-4 Count'] = X_train['IME-4 Count'].fillna(0)\n",
    "#         X_val['IME-4 Count'] = X_val['IME-4 Count'].fillna(0)\n",
    "#         test['IME-4 Count'] = test['IME-4 Count'].fillna(0)\n",
    "\n",
    "#         X_train['Industry Code'] = X_train['Industry Code'].fillna(0)\n",
    "#         X_val['Industry Code'] = X_val['Industry Code'].fillna(0)\n",
    "#         test['Industry Code'] = test['Industry Code'].fillna(0)\n",
    "\n",
    "#         p.fill_dates(X_train, [X_val, test], 'Accident Date')\n",
    "#         p.fill_dates(X_train, [X_val, test], 'C-2 Date')\n",
    "\n",
    "#         p.fill_dow([X_train, X_val, test], 'Accident Date')\n",
    "#         p.fill_dow([X_train, X_val, test], 'C-2 Date')\n",
    "\n",
    "#         X_train = p.fill_missing_times(X_train, ['Accident to Assembly Time', \n",
    "#                                  'Assembly to C-2 Time',\n",
    "#                                  'Accident to C-2 Time'])\n",
    "\n",
    "#         X_val = p.fill_missing_times(X_val, ['Accident to Assembly Time', \n",
    "#                                  'Assembly to C-2 Time',\n",
    "#                                  'Accident to C-2 Time'])\n",
    "\n",
    "#         test = p.fill_missing_times(test, ['Accident to Assembly Time', \n",
    "#                                  'Assembly to C-2 Time',\n",
    "#                                  'Accident to C-2 Time'])\n",
    "\n",
    "#         p.fill_birth_year([X_train, X_val, test])\n",
    "\n",
    "\n",
    "#         # Variables\n",
    "#         num = ['Age at Injury', 'Average Weekly Wage', 'Birth Year',\n",
    "#            'IME-4 Count', 'Number of Dependents', 'Accident Date Year',\n",
    "#            'Accident Date Month', 'Accident Date Day', \n",
    "#            'Assembly Date Year', 'Assembly Date Month', \n",
    "#            'Assembly Date Day', 'C-2 Date Year', 'C-2 Date Month',\n",
    "#            'C-2 Date Day', 'Accident to Assembly Time',\n",
    "#            'Assembly to C-2 Time', 'Accident to C-2 Time']\n",
    "#           # 'Wage to Age Ratio', 'Average Weekly Wage Sqrt',\n",
    "#           # 'IME-4 Count Log', 'IME-4 Count Double Log']\n",
    "\n",
    "\n",
    "#         categ = [var for var in X_train.columns if var not in num]\n",
    "\n",
    "#         categ_count_encoding = ['Carrier Name Enc', 'Carrier Type Enc',\n",
    "#                                 'County of Injury Enc', 'District Name Enc',\n",
    "#                                 'Medical Fee Region Enc', \n",
    "#                                 'Industry Sector Enc']\n",
    "\n",
    "\n",
    "#         categ_label_bin = [var for var in X_train.columns if var\n",
    "#                            in categ and var not in categ_count_encoding]\n",
    "\n",
    "#         num_count_enc = num + categ_count_encoding\n",
    "\n",
    "\n",
    "#         # Scale\n",
    "#         robust = RobustScaler()\n",
    "\n",
    "#         X_train_num_count_enc_RS = robust.fit_transform(X_train[num_count_enc])\n",
    "#         X_train_num_count_enc_RS = pd.DataFrame(X_train_num_count_enc_RS, columns=num_count_enc, index=X_train.index)\n",
    "#         X_val_num_count_enc_RS = robust.transform(X_val[num_count_enc])\n",
    "#         X_val_num_count_enc_RS = pd.DataFrame(X_val_num_count_enc_RS, columns=num_count_enc, index=X_val.index)\n",
    "#         test_num_count_enc_RS = robust.transform(test[num_count_enc])\n",
    "#         test_num_count_enc_RS = pd.DataFrame(test_num_count_enc_RS, columns=num_count_enc, index=test.index)\n",
    "\n",
    "#         X_train_RS = pd.concat([X_train_num_count_enc_RS, \n",
    "#                                 X_train[categ_label_bin]], axis=1)\n",
    "#         X_val_RS = pd.concat([X_val_num_count_enc_RS, \n",
    "#                               X_val[categ_label_bin]], axis=1)\n",
    "#         test_RS = pd.concat([test_num_count_enc_RS, \n",
    "#                              test[categ_label_bin]], axis=1)\n",
    "\n",
    "#         p.ball_tree_impute([X_train_RS, X_val_RS, test_RS], \n",
    "#                            'Average Weekly Wage')\n",
    "        \n",
    "#         if outliers:\n",
    "#             X_train_RS = X_train_RS[X_train_RS['Age at Injury'] < 2.0217391304347827]\n",
    "            \n",
    "#             X_train_RS['Average Weekly Wage Sqrt'] = np.sqrt(X_train_RS['Average Weekly Wage'])\n",
    "\n",
    "#             X_val_RS['Average Weekly Wage Sqrt'] = np.sqrt(X_val_RS['Average Weekly Wage'])\n",
    "\n",
    "#             test_RS['Average Weekly Wage Sqrt'] = np.sqrt(test_RS['Average Weekly Wage'])\n",
    "            \n",
    "#             upper_limit = X_train_RS['Average Weekly Wage'].quantile(0.99)\n",
    "#             lower_limit = X_train_RS['Average Weekly Wage'].quantile(0.01)\n",
    "\n",
    "#             X_train_RS['Average Weekly Wage'] = X_train_RS['Average Weekly Wage'].clip(lower = lower_limit\n",
    "#                                                                   , upper=upper_limit)\n",
    "            \n",
    "#             X_train_RS = X_train_RS[X_train_RS['Birth Year'] > -1.9782608695652173]\n",
    "            \n",
    "#             X_train_RS['IME-4 Count Log'] = np.log1p(X_train_RS['IME-4 Count'])\n",
    "#             X_train_RS['IME-4 Count Double Log'] = np.log1p(X_train_RS['IME-4 Count Log'])\n",
    "\n",
    "#             X_val_RS['IME-4 Count Log'] = np.log1p(X_val_RS['IME-4 Count'])\n",
    "#             X_val_RS['IME-4 Count Double Log'] = np.log1p(X_val_RS['IME-4 Count Log'])\n",
    "\n",
    "#             test_RS['IME-4 Count Log'] = np.log1p(test_RS['IME-4 Count'])\n",
    "#             test_RS['IME-4 Count Double Log'] = np.log1p(test_RS['IME-4 Count Log'])\n",
    "            \n",
    "#             X_train_RS = X_train_RS[X_train_RS['Accident Date Year'] > -2.0]\n",
    "            \n",
    "#             X_train_RS = X_train_RS[X_train_RS['C-2 Date Year'] > -2.0]\n",
    "            \n",
    "#             y_train = y_train[X_train_RS.index]\n",
    "\n",
    "#         # Training\n",
    "#         model = run_model(model_name, X_train_RS, y_train, params.get(model_name, {}))\n",
    "\n",
    "#         # Predictions\n",
    "#         pred_train = model.predict(X_train_RS)\n",
    "#         pred_val = model.predict(X_val_RS)\n",
    "        \n",
    "#         test_preds = model.predict_proba(test_RS)\n",
    "\n",
    "#         # Metrics\n",
    "#         f1macro_train.append(f1_score(y_train, pred_train, average='macro'))\n",
    "#         f1macro_val.append(f1_score(y_val, pred_val, average='macro'))\n",
    "#         precision_train.append(precision_score(y_train, pred_train, average='macro')) \n",
    "#         precision_val.append(precision_score(y_val, pred_val, average='macro'))  \n",
    "#         recall_train.append(recall_score(y_train, pred_train, average='macro'))\n",
    "#         recall_val.append(recall_score(y_val, pred_val, average='macro'))\n",
    "        \n",
    "#         # Compute Time\n",
    "#         end_time = time.time()\n",
    "#         elapsed_time = round((end_time - start_time) / 60, 2)\n",
    "#         timer.append(elapsed_time) \n",
    "#         print(f'This Fold took {elapsed_time} minutes')\n",
    "\n",
    "#     # Metrics Average and Stdev\n",
    "#     avg_time = round(np.mean(timer), 3)\n",
    "#     avg_f1_train = round(np.mean(f1macro_train), 3)\n",
    "#     avg_f1_val = round(np.mean(f1macro_val), 3)\n",
    "#     avg_precision_train = round(np.mean(precision_train), 3)\n",
    "#     avg_precision_val = round(np.mean(precision_val), 3)\n",
    "#     avg_recall_train = round(np.mean(recall_train), 3)\n",
    "#     avg_recall_val = round(np.mean(recall_val), 3)\n",
    "#     std_time = round(np.std(timer), 3)\n",
    "#     std_f1_train = round(np.std(f1macro_train), 3)\n",
    "#     std_f1_val = round(np.std(f1macro_val), 3)\n",
    "#     std_precision_train = round(np.std(precision_train), 3)\n",
    "#     std_precision_val = round(np.std(precision_val), 3)\n",
    "#     std_recall_train = round(np.std(recall_train), 3)\n",
    "#     std_recall_val = round(np.std(recall_val), 3)\n",
    "\n",
    "#     # Final Predictions using Soft Voting\n",
    "#     threshold = 0.5\n",
    "#     y_custom_pred = np.array([custom_predict(test_preds[i], \n",
    "#                                              threshold) for i in range(len(test_preds))])\n",
    "\n",
    "#     test_RS['Claim Injury Type'] = y_custom_pred \n",
    "\n",
    "#     test_RS['Claim Injury Type'] = test_RS['Claim Injury Type'].replace(label_mapping)\n",
    "    \n",
    "#     predictions = test_RS['Claim Injury Type']\n",
    "    \n",
    "#     if file_name != None:\n",
    "    \n",
    "#         predictions.to_csv(f'./pred/{file_name}.csv')\n",
    "\n",
    "\n",
    "#     # Return data and treated Test_RS\n",
    "#     return {\n",
    "#         'avg_time': str(avg_time) + '+/-' + str(std_time),\n",
    "#         'avg_f1_train': str(avg_f1_train) + '+/-' + str(std_f1_train),\n",
    "#         'avg_f1_val': str(avg_f1_val) + '+/-' + str(std_f1_val),\n",
    "#         'avg_precision_train': str(avg_precision_train) + '+/-' + str(std_precision_train),\n",
    "#         'avg_precision_val': str(avg_precision_val) + '+/-' + str(std_precision_val),\n",
    "#         'avg_recall_train': str(avg_recall_train) + '+/-' + str(std_recall_train),\n",
    "#         'avg_recall_val': str(avg_recall_val) + '+/-' + str(std_recall_val),\n",
    "#         'test_data': test_RS,\n",
    "#         'predictions': predictions}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T19:26:43.180339Z",
     "start_time": "2024-12-16T19:26:43.177373Z"
    }
   },
   "outputs": [],
   "source": [
    "method = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T19:34:50.347999Z",
     "start_time": "2024-12-16T19:31:17.220728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Fold took 1.15 minutes\n",
      "This Fold took 1.2 minutes\n",
      "This Fold took 1.15 minutes\n"
     ]
    }
   ],
   "source": [
    "try5 = k_fold(method, X, y, test1, 'XGB', params = {},\n",
    "                              enc = 'freq', outliers = True,\n",
    "                              file_name = 'try5')\n",
    "\n",
    "# try1 = simple soft voting\n",
    "# try2 = 0.1\n",
    "# try3 = 0.05\n",
    "# try4 = 0.2\n",
    "# try5 = 0.5\n",
    "# above the fold is what appears when one opens the website -> DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T18:01:39.171277Z",
     "start_time": "2024-12-16T18:01:39.171254Z"
    }
   },
   "outputs": [],
   "source": [
    "models = [try2]\n",
    "\n",
    "model_names = ['try2']\n",
    "\n",
    "m.metrics2(models, model_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
