{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Machine Learning Project Code</center>\n",
    "\n",
    "<a class=\"anchor\" id=\"top\"></a>\n",
    "\n",
    "## <center>*03 - K-Fold*</center>\n",
    "\n",
    "** **\n",
    "\n",
    "\n",
    "\n",
    "# Table of Contents  <br>\n",
    "\n",
    "\n",
    "1. [Importing Libraries & Data](#1.-Importing-Libraries-&-Data) <br><br>\n",
    "    \n",
    "2. [Cross Validation](#2.-Cross-Validation) <br><br>\n",
    "\n",
    "3. [Final Predictions](#3.-Final-Predictions) <br><br>\n",
    "\n",
    "** **\n",
    "\n",
    "This notebook will consist of the implementation of Stratified K-Fold. It will use the same techniques to fill missing values and treat outliers as Notebook 02. Feature Selection will only be performed in said notebook, and the selected features there will be used here, due to computational complexity and time constraints.\n",
    "\n",
    "Data Scientist Manager: António Oliveira, **20211595**\n",
    "\n",
    "Data Scientist Senior: Tomás Ribeiro, **20240526**\n",
    "\n",
    "Data Scientist Junior: Gonçalo Pacheco, **20240695**\n",
    "\n",
    "Data Analyst Senior: Gonçalo Custódio, **20211643**\n",
    "\n",
    "Data Analyst Junior: Ana Caleiro, **20240696**\n",
    "\n",
    "\n",
    "** ** \n",
    "\n",
    "# 1. Importing Libraries & Data\n",
    "In this section, we set up the foundation for our project by importing the necessary Python libraries and loading the dataset. These libraries provide the tools for data manipulation, visualization, and machine learning modeling throughout the notebook. Additionally, we import the historical claims dataset, which forms the core of our analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T18:01:01.706035Z",
     "start_time": "2024-12-14T18:01:01.699889Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Train-Test Split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Models\n",
    "import models as mod\n",
    "\n",
    "# Metrics\n",
    "import metrics as m\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Suppress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T17:56:04.166261Z",
     "start_time": "2024-12-14T17:55:59.591698Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age at Injury</th>\n",
       "      <th>Alternative Dispute Resolution</th>\n",
       "      <th>Attorney/Representative</th>\n",
       "      <th>Average Weekly Wage</th>\n",
       "      <th>Birth Year</th>\n",
       "      <th>C-3 Date</th>\n",
       "      <th>Carrier Name</th>\n",
       "      <th>Carrier Type</th>\n",
       "      <th>Claim Injury Type</th>\n",
       "      <th>County of Injury</th>\n",
       "      <th>COVID-19 Indicator</th>\n",
       "      <th>District Name</th>\n",
       "      <th>First Hearing Date</th>\n",
       "      <th>Gender</th>\n",
       "      <th>IME-4 Count</th>\n",
       "      <th>Industry Code</th>\n",
       "      <th>Medical Fee Region</th>\n",
       "      <th>WCIO Cause of Injury Code</th>\n",
       "      <th>WCIO Nature of Injury Code</th>\n",
       "      <th>WCIO Part Of Body Code</th>\n",
       "      <th>Number of Dependents</th>\n",
       "      <th>Gender Enc</th>\n",
       "      <th>Accident Date Year</th>\n",
       "      <th>Accident Date Month</th>\n",
       "      <th>Accident Date Day</th>\n",
       "      <th>Accident Date Day of Week</th>\n",
       "      <th>Assembly Date Year</th>\n",
       "      <th>Assembly Date Month</th>\n",
       "      <th>Assembly Date Day</th>\n",
       "      <th>Assembly Date Day of Week</th>\n",
       "      <th>C-2 Date Year</th>\n",
       "      <th>C-2 Date Month</th>\n",
       "      <th>C-2 Date Day</th>\n",
       "      <th>C-2 Date Day of Week</th>\n",
       "      <th>Accident to Assembly Time</th>\n",
       "      <th>Assembly to C-2 Time</th>\n",
       "      <th>Accident to C-2 Time</th>\n",
       "      <th>WCIO Codes</th>\n",
       "      <th>Insurance</th>\n",
       "      <th>Zip Code Valid</th>\n",
       "      <th>Industry Sector</th>\n",
       "      <th>Age Group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Claim Identifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5393875</th>\n",
       "      <td>31.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEW HAMPSHIRE INSURANCE CO</td>\n",
       "      <td>1A. PRIVATE</td>\n",
       "      <td>1</td>\n",
       "      <td>ST. LAWRENCE</td>\n",
       "      <td>N</td>\n",
       "      <td>SYRACUSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>I</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>271062</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Retail and Wholesale</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5393091</th>\n",
       "      <td>46.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>1745.93</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>ZURICH AMERICAN INSURANCE CO</td>\n",
       "      <td>1A. PRIVATE</td>\n",
       "      <td>3</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>N</td>\n",
       "      <td>ROCHESTER</td>\n",
       "      <td>2020-02-21</td>\n",
       "      <td>F</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>I</td>\n",
       "      <td>97</td>\n",
       "      <td>49</td>\n",
       "      <td>38</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>974938</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Manufacturing and Construction</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5393889</th>\n",
       "      <td>40.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1434.80</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INDEMNITY INSURANCE CO OF</td>\n",
       "      <td>1A. PRIVATE</td>\n",
       "      <td>3</td>\n",
       "      <td>ORANGE</td>\n",
       "      <td>N</td>\n",
       "      <td>ALBANY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "      <td>II</td>\n",
       "      <td>79</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>79710</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Business Services</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Age at Injury Alternative Dispute Resolution  \\\n",
       "Claim Identifier                                                 \n",
       "5393875                    31.0                              N   \n",
       "5393091                    46.0                              N   \n",
       "5393889                    40.0                              N   \n",
       "\n",
       "                 Attorney/Representative  Average Weekly Wage  Birth Year  \\\n",
       "Claim Identifier                                                            \n",
       "5393875                                N                 0.00      1988.0   \n",
       "5393091                                Y              1745.93      1973.0   \n",
       "5393889                                N              1434.80      1979.0   \n",
       "\n",
       "                    C-3 Date                  Carrier Name Carrier Type  \\\n",
       "Claim Identifier                                                          \n",
       "5393875                  NaN    NEW HAMPSHIRE INSURANCE CO  1A. PRIVATE   \n",
       "5393091           2020-01-14  ZURICH AMERICAN INSURANCE CO  1A. PRIVATE   \n",
       "5393889                  NaN     INDEMNITY INSURANCE CO OF  1A. PRIVATE   \n",
       "\n",
       "                  Claim Injury Type County of Injury COVID-19 Indicator  \\\n",
       "Claim Identifier                                                          \n",
       "5393875                           1     ST. LAWRENCE                  N   \n",
       "5393091                           3          WYOMING                  N   \n",
       "5393889                           3           ORANGE                  N   \n",
       "\n",
       "                 District Name First Hearing Date Gender  IME-4 Count  \\\n",
       "Claim Identifier                                                        \n",
       "5393875               SYRACUSE                NaN      M          NaN   \n",
       "5393091              ROCHESTER         2020-02-21      F          4.0   \n",
       "5393889                 ALBANY                NaN      M          NaN   \n",
       "\n",
       "                  Industry Code Medical Fee Region  WCIO Cause of Injury Code  \\\n",
       "Claim Identifier                                                                \n",
       "5393875                    44.0                  I                         27   \n",
       "5393091                    23.0                  I                         97   \n",
       "5393889                    56.0                 II                         79   \n",
       "\n",
       "                  WCIO Nature of Injury Code  WCIO Part Of Body Code  \\\n",
       "Claim Identifier                                                       \n",
       "5393875                                   10                      62   \n",
       "5393091                                   49                      38   \n",
       "5393889                                    7                      10   \n",
       "\n",
       "                  Number of Dependents  Gender Enc  Accident Date Year  \\\n",
       "Claim Identifier                                                         \n",
       "5393875                            1.0           0              2019.0   \n",
       "5393091                            4.0           1              2019.0   \n",
       "5393889                            6.0           0              2019.0   \n",
       "\n",
       "                  Accident Date Month  Accident Date Day  \\\n",
       "Claim Identifier                                           \n",
       "5393875                          12.0               30.0   \n",
       "5393091                           8.0               30.0   \n",
       "5393889                          12.0                6.0   \n",
       "\n",
       "                  Accident Date Day of Week  Assembly Date Year  \\\n",
       "Claim Identifier                                                  \n",
       "5393875                                 0.0                2020   \n",
       "5393091                                 4.0                2020   \n",
       "5393889                                 4.0                2020   \n",
       "\n",
       "                  Assembly Date Month  Assembly Date Day  \\\n",
       "Claim Identifier                                           \n",
       "5393875                             1                  1   \n",
       "5393091                             1                  1   \n",
       "5393889                             1                  1   \n",
       "\n",
       "                  Assembly Date Day of Week  C-2 Date Year  C-2 Date Month  \\\n",
       "Claim Identifier                                                             \n",
       "5393875                                   2         2019.0            12.0   \n",
       "5393091                                   2         2020.0             1.0   \n",
       "5393889                                   2         2020.0             1.0   \n",
       "\n",
       "                  C-2 Date Day  C-2 Date Day of Week  \\\n",
       "Claim Identifier                                       \n",
       "5393875                   31.0                   1.0   \n",
       "5393091                    1.0                   2.0   \n",
       "5393889                    1.0                   2.0   \n",
       "\n",
       "                  Accident to Assembly Time  Assembly to C-2 Time  \\\n",
       "Claim Identifier                                                    \n",
       "5393875                                 2.0                   1.0   \n",
       "5393091                               124.0                   0.0   \n",
       "5393889                                26.0                   0.0   \n",
       "\n",
       "                  Accident to C-2 Time  WCIO Codes  Insurance  Zip Code Valid  \\\n",
       "Claim Identifier                                                                \n",
       "5393875                            1.0      271062          1               0   \n",
       "5393091                          124.0      974938          1               0   \n",
       "5393889                           26.0       79710          1               0   \n",
       "\n",
       "                                 Industry Sector  Age Group  \n",
       "Claim Identifier                                             \n",
       "5393875                     Retail and Wholesale          1  \n",
       "5393091           Manufacturing and Construction          1  \n",
       "5393889                        Business Services          1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training data\n",
    "df = pd.read_csv('./data/train_data_EDA.csv', index_col = 'Claim Identifier')\n",
    "\n",
    "# Load testing data\n",
    "test1 = pd.read_csv('./data/test_data_EDA.csv', index_col = 'Claim Identifier')\n",
    "\n",
    "# Display the first 3 rows of the training data\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Cross Validation\n",
    "\n",
    "<a href=\"#top\">Top &#129033;</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WORK IN PROGRESS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T22:26:26.903873Z",
     "start_time": "2024-12-17T22:26:26.865788Z"
    }
   },
   "outputs": [],
   "source": [
    "# \n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Preprocessing\n",
    "import utils2 as p\n",
    "\n",
    "# Scalers\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    MinMaxScaler,\n",
    "    RobustScaler)\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, \\\n",
    "    GradientBoostingClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier \n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# Oversampling, Undersmpling and SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "\n",
    "def run_model(model_name, X, y, params = None):\n",
    "\n",
    "    if params is None:\n",
    "        params = {}\n",
    "\n",
    "    if model_name == 'LR':\n",
    "        model = LogisticRegression(**params).fit(X, y)\n",
    "    elif model_name == 'SGD':\n",
    "        model = SGDClassifier(**params).fit(X, y)\n",
    "    elif model_name == 'DT':\n",
    "        model = DecisionTreeClassifier(**params).fit(X, y)\n",
    "    elif model_name == 'RF':\n",
    "        model = RandomForestClassifier(**params).fit(X, y)\n",
    "    elif model_name == 'AdaBoost':\n",
    "        model = AdaBoostClassifier(**params).fit(X, y)\n",
    "    elif model_name == 'GBoost':\n",
    "        model = GradientBoostingClassifier(**params).fit(X, y)\n",
    "    elif model_name == 'XGB':\n",
    "        model = XGBClassifier(**params).fit(X, y)\n",
    "    elif model_name == 'MLP':\n",
    "        model = MLPClassifier(**params).fit(X, y)\n",
    "    elif model_name == 'GNB':  \n",
    "        model = GaussianNB().fit(X, y)\n",
    "    elif model_name == 'CNB':  \n",
    "        model = CategoricalNB().fit(X, y)\n",
    "    elif model_name == 'KNN':  \n",
    "        model = KNeighborsClassifier(**params).fit(X, y)\n",
    "    elif model_name == 'LGBM':  \n",
    "        model = LGBMClassifier(**params).fit(X, y)\n",
    "    elif model_name == 'SVM':  \n",
    "        model = SVC(**params).fit(X, y)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def k_fold(method, X, y, test1, model_name, \n",
    "           params, enc, outliers = False,\n",
    "           file_name = None,\n",
    "           under_sample = False, over_sample = False):\n",
    "     \n",
    "    if over_sample:\n",
    "        oversampler = RandomOverSampler(random_state=42, sampling_strategy='auto') \n",
    "    if under_sample:\n",
    "        undersampler = RandomUnderSampler(random_state=42, \n",
    "                                          sampling_strategy='auto')\n",
    "                                                                \n",
    "\n",
    "    # Save metrics\n",
    "    f1macro_train = []\n",
    "    f1macro_val = []\n",
    "    precision_train = []\n",
    "    precision_val = []\n",
    "    recall_train = []\n",
    "    recall_val = []\n",
    "    timer = []\n",
    "    \n",
    "    # Mapping\n",
    "    label_mapping = {\n",
    "        0: \"1. CANCELLED\",\n",
    "        1: \"2. NON-COMP\",\n",
    "        2: \"3. MED ONLY\",\n",
    "        3: \"4. TEMPORARY\",\n",
    "        4: \"5. PPD SCH LOSS\",\n",
    "        5: \"6. PPD NSL\",\n",
    "        6: \"7. PTD\",\n",
    "        7: \"8. DEATH\"}\n",
    "    \n",
    "    test_preds = np.zeros((len(test1), len(label_mapping)))\n",
    "\n",
    "\n",
    "    # For each fold\n",
    "    for train_index, val_index in method.split(X, y):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "        test = test1.copy()\n",
    "\n",
    "        start_time = time.time()\n",
    "        \n",
    "\n",
    "        # ENCODING\n",
    "        X_train['Alternative Dispute Resolution Bin'] = X_train['Alternative Dispute Resolution'].replace({'N': 0, 'Y': 1, 'U': 1})\n",
    "        X_val['Alternative Dispute Resolution Bin'] = X_val['Alternative Dispute Resolution'].replace({'N': 0, 'Y': 1, 'U': 1})\n",
    "        test['Alternative Dispute Resolution Bin'] = test['Alternative Dispute Resolution'].replace({'N': 0, 'Y': 1, 'U': 1})\n",
    "\n",
    "        X_train['Attorney/Representative Bin'] = X_train['Attorney/Representative'].replace({'N': 0, 'Y': 1})\n",
    "        X_val['Attorney/Representative Bin'] = X_val['Attorney/Representative'].replace({'N': 0, 'Y': 1})\n",
    "        test['Attorney/Representative Bin'] = test['Attorney/Representative'].replace({'N': 0, 'Y': 1})\n",
    "\n",
    "        train_carriers = set(X_train['Carrier Name'].unique())\n",
    "        test_carriers = set(test['Carrier Name'].unique())\n",
    "        common_categories = train_carriers.intersection(test_carriers)\n",
    "        common_category_map = {category: idx + 1 for idx, \n",
    "                           category in enumerate(common_categories)}\n",
    "\n",
    "        X_train['Carrier Name Enc'] = X_train['Carrier Name'].map(common_category_map).fillna(0).astype(int)\n",
    "        X_val['Carrier Name Enc'] = X_val['Carrier Name'].map(common_category_map).fillna(0).astype(int)\n",
    "        test['Carrier Name Enc'] = test['Carrier Name'].map(common_category_map).fillna(0).astype(int)\n",
    "\n",
    "        X_train, X_val, test = p.encode(X_train, X_val, test, 'Carrier Name Enc', enc)\n",
    "\n",
    "        X_train, X_val, test = p.encode(X_train, X_val, test, 'Carrier Type', enc)\n",
    "        X_train, X_val, test = p.encode(X_train, X_val, test, 'Carrier Type', 'OHE')\n",
    "\n",
    "        X_train, X_val, test = p.encode(X_train, X_val, test, 'County of Injury', enc)\n",
    "\n",
    "        X_train['COVID-19 Indicator Enc'] = X_train['COVID-19 Indicator'].replace({'N': 0, 'Y': 1})\n",
    "        X_val['COVID-19 Indicator Enc'] = X_val['COVID-19 Indicator'].replace({'N': 0, 'Y': 1})\n",
    "        test['COVID-19 Indicator Enc'] = test['COVID-19 Indicator'].replace({'N': 0, 'Y': 1})\n",
    "\n",
    "        X_train, X_val, test = p.encode(X_train, X_val, test, 'District Name', enc)\n",
    "\n",
    "        X_train, X_val, test = p.encode(X_train, X_val, test, 'Gender', 'OHE')\n",
    "\n",
    "        X_train, X_val, test = p.encode(X_train, X_val, test, 'Medical Fee Region', enc)\n",
    "\n",
    "        X_train, X_val, test = p.encode(X_train, X_val, test, 'Industry Sector', enc)\n",
    "\n",
    "        drop = ['Alternative Dispute Resolution', 'Attorney/Representative', 'Carrier Type', 'County of Injury',\n",
    "                'COVID-19 Indicator', 'District Name', 'Gender', 'Carrier Name',\n",
    "                'Medical Fee Region', 'Industry Sector']\n",
    "\n",
    "        X_train.drop(columns = drop, axis = 1, inplace = True)\n",
    "        X_val.drop(columns = drop, axis = 1, inplace = True)\n",
    "        test.drop(columns = drop, axis = 1, inplace = True)\n",
    "\n",
    "        # MISSING VALUES\n",
    "        X_train['C-3 Date Binary'] = X_train['C-3 Date'].notna().astype(int)\n",
    "        X_val['C-3 Date Binary'] = X_val['C-3 Date'].notna().astype(int)\n",
    "        test['C-3 Date Binary'] = test['C-3 Date'].notna().astype(int)\n",
    "\n",
    "        X_train['First Hearing Date Binary'] = X_train['First Hearing Date'].notna().astype(int)\n",
    "        X_val['First Hearing Date Binary'] = X_val['First Hearing Date'].notna().astype(int)\n",
    "        test['First Hearing Date Binary'] = test['First Hearing Date'].notna().astype(int)\n",
    "\n",
    "        drop = ['C-3 Date', 'First Hearing Date']\n",
    "        X_train.drop(columns = drop, axis = 1, inplace = True)\n",
    "        X_val.drop(columns = drop, axis = 1, inplace = True)\n",
    "        test.drop(columns = drop, axis = 1, inplace = True)\n",
    "\n",
    "        X_train['IME-4 Count'] = X_train['IME-4 Count'].fillna(0)\n",
    "        X_val['IME-4 Count'] = X_val['IME-4 Count'].fillna(0)\n",
    "        test['IME-4 Count'] = test['IME-4 Count'].fillna(0)\n",
    "\n",
    "        X_train['Industry Code'] = X_train['Industry Code'].fillna(0)\n",
    "        X_val['Industry Code'] = X_val['Industry Code'].fillna(0)\n",
    "        test['Industry Code'] = test['Industry Code'].fillna(0)\n",
    "\n",
    "        p.fill_dates(X_train, [X_val, test], 'Accident Date')\n",
    "        p.fill_dates(X_train, [X_val, test], 'C-2 Date')\n",
    "\n",
    "        p.fill_dow([X_train, X_val, test], 'Accident Date')\n",
    "        p.fill_dow([X_train, X_val, test], 'C-2 Date')\n",
    "\n",
    "        X_train = p.fill_missing_times(X_train, ['Accident to Assembly Time', \n",
    "                                 'Assembly to C-2 Time',\n",
    "                                 'Accident to C-2 Time'])\n",
    "\n",
    "        X_val = p.fill_missing_times(X_val, ['Accident to Assembly Time', \n",
    "                                 'Assembly to C-2 Time',\n",
    "                                 'Accident to C-2 Time'])\n",
    "\n",
    "        test = p.fill_missing_times(test, ['Accident to Assembly Time', \n",
    "                                 'Assembly to C-2 Time',\n",
    "                                 'Accident to C-2 Time'])\n",
    "\n",
    "        p.fill_birth_year([X_train, X_val, test])\n",
    "\n",
    "\n",
    "        # Variables\n",
    "        num = ['Age at Injury', 'Average Weekly Wage', 'Birth Year',\n",
    "           'IME-4 Count', 'Number of Dependents', 'Accident Date Year',\n",
    "           'Accident Date Month', 'Accident Date Day', \n",
    "           'Assembly Date Year', 'Assembly Date Month', \n",
    "           'Assembly Date Day', 'C-2 Date Year', 'C-2 Date Month',\n",
    "           'C-2 Date Day', 'Accident to Assembly Time',\n",
    "           'Assembly to C-2 Time', 'Accident to C-2 Time']\n",
    "          # 'Wage to Age Ratio', 'Average Weekly Wage Sqrt',\n",
    "          # 'IME-4 Count Log', 'IME-4 Count Double Log']\n",
    "\n",
    "\n",
    "        categ = [var for var in X_train.columns if var not in num]\n",
    "\n",
    "        categ_count_encoding = ['Carrier Name Enc', 'Carrier Type Enc',\n",
    "                                'County of Injury Enc', 'District Name Enc',\n",
    "                                'Medical Fee Region Enc', \n",
    "                                'Industry Sector Enc']\n",
    "\n",
    "\n",
    "        categ_label_bin = [var for var in X_train.columns if var\n",
    "                           in categ and var not in categ_count_encoding]\n",
    "\n",
    "        num_count_enc = num + categ_count_encoding\n",
    "\n",
    "\n",
    "        # Scale\n",
    "        robust = RobustScaler()\n",
    "\n",
    "        X_train_num_count_enc_RS = robust.fit_transform(X_train[num_count_enc])\n",
    "        X_train_num_count_enc_RS = pd.DataFrame(X_train_num_count_enc_RS, columns=num_count_enc, index=X_train.index)\n",
    "        X_val_num_count_enc_RS = robust.transform(X_val[num_count_enc])\n",
    "        X_val_num_count_enc_RS = pd.DataFrame(X_val_num_count_enc_RS, columns=num_count_enc, index=X_val.index)\n",
    "        test_num_count_enc_RS = robust.transform(test[num_count_enc])\n",
    "        test_num_count_enc_RS = pd.DataFrame(test_num_count_enc_RS, columns=num_count_enc, index=test.index)\n",
    "\n",
    "        X_train_RS = pd.concat([X_train_num_count_enc_RS, \n",
    "                                X_train[categ_label_bin]], axis=1)\n",
    "        X_val_RS = pd.concat([X_val_num_count_enc_RS, \n",
    "                              X_val[categ_label_bin]], axis=1)\n",
    "        test_RS = pd.concat([test_num_count_enc_RS, \n",
    "                             test[categ_label_bin]], axis=1)\n",
    "\n",
    "        p.ball_tree_impute([X_train_RS, X_val_RS, test_RS], \n",
    "                           'Average Weekly Wage')\n",
    "        \n",
    "        if outliers:\n",
    "            X_train_RS = X_train_RS[X_train_RS['Age at Injury'] < 2.0217391304347827]\n",
    "            \n",
    "            X_train_RS['Average Weekly Wage Sqrt'] = np.sqrt(X_train_RS['Average Weekly Wage'])\n",
    "\n",
    "            X_val_RS['Average Weekly Wage Sqrt'] = np.sqrt(X_val_RS['Average Weekly Wage'])\n",
    "\n",
    "            test_RS['Average Weekly Wage Sqrt'] = np.sqrt(test_RS['Average Weekly Wage'])\n",
    "            \n",
    "            upper_limit = X_train_RS['Average Weekly Wage'].quantile(0.99)\n",
    "            lower_limit = X_train_RS['Average Weekly Wage'].quantile(0.01)\n",
    "\n",
    "            X_train_RS['Average Weekly Wage'] = X_train_RS['Average Weekly Wage'].clip(lower = lower_limit\n",
    "                                                                  , upper=upper_limit)\n",
    "            \n",
    "            X_train_RS = X_train_RS[X_train_RS['Birth Year'] > -1.9782608695652173]\n",
    "            \n",
    "            X_train_RS['IME-4 Count Log'] = np.log1p(X_train_RS['IME-4 Count'])\n",
    "            X_train_RS['IME-4 Count Double Log'] = np.log1p(X_train_RS['IME-4 Count Log'])\n",
    "\n",
    "            X_val_RS['IME-4 Count Log'] = np.log1p(X_val_RS['IME-4 Count'])\n",
    "            X_val_RS['IME-4 Count Double Log'] = np.log1p(X_val_RS['IME-4 Count Log'])\n",
    "\n",
    "            test_RS['IME-4 Count Log'] = np.log1p(test_RS['IME-4 Count'])\n",
    "            test_RS['IME-4 Count Double Log'] = np.log1p(test_RS['IME-4 Count Log'])\n",
    "            \n",
    "            X_train_RS = X_train_RS[X_train_RS['Accident Date Year'] > -2.0]\n",
    "            \n",
    "            X_train_RS = X_train_RS[X_train_RS['C-2 Date Year'] > -2.0]\n",
    "            \n",
    "            y_train = y_train[X_train_RS.index]\n",
    "            \n",
    "            \n",
    "        # Oversampling and Undersmpling\n",
    "        if over_sample:\n",
    "            X_train_RS, y_train = oversampler.fit_resample(X_train_RS, y_train)\n",
    "\n",
    "        elif under_sample:\n",
    "            X_train_RS, y_train = undersampler.fit_resample(X_train_RS, y_train)\n",
    "            \n",
    "            \n",
    "        print(y_train.value_counts())\n",
    "\n",
    "\n",
    "        # Training\n",
    "        model = run_model(model_name, X_train_RS, y_train, params.get(model_name, {}))\n",
    "\n",
    "        # Predictions\n",
    "        pred_train = model.predict(X_train_RS)\n",
    "        pred_val = model.predict(X_val_RS)\n",
    "        \n",
    "        test_preds += model.predict_proba(test_RS)\n",
    "\n",
    "        # Metrics\n",
    "        f1macro_train.append(f1_score(y_train, pred_train, average='macro'))\n",
    "        f1macro_val.append(f1_score(y_val, pred_val, average='macro'))\n",
    "        precision_train.append(precision_score(y_train, pred_train, average='macro')) \n",
    "        precision_val.append(precision_score(y_val, pred_val, average='macro'))  \n",
    "        recall_train.append(recall_score(y_train, pred_train, average='macro'))\n",
    "        recall_val.append(recall_score(y_val, pred_val, average='macro'))\n",
    "        \n",
    "        # Compute Time\n",
    "        end_time = time.time()\n",
    "        elapsed_time = round((end_time - start_time) / 60, 2)\n",
    "        timer.append(elapsed_time) \n",
    "        print(f'This Fold took {elapsed_time} minutes')\n",
    "\n",
    "    # Metrics Average and Stdev\n",
    "    avg_time = round(np.mean(timer), 3)\n",
    "    avg_f1_train = round(np.mean(f1macro_train), 3)\n",
    "    avg_f1_val = round(np.mean(f1macro_val), 3)\n",
    "    avg_precision_train = round(np.mean(precision_train), 3)\n",
    "    avg_precision_val = round(np.mean(precision_val), 3)\n",
    "    avg_recall_train = round(np.mean(recall_train), 3)\n",
    "    avg_recall_val = round(np.mean(recall_val), 3)\n",
    "    std_time = round(np.std(timer), 3)\n",
    "    std_f1_train = round(np.std(f1macro_train), 3)\n",
    "    std_f1_val = round(np.std(f1macro_val), 3)\n",
    "    std_precision_train = round(np.std(precision_train), 3)\n",
    "    std_precision_val = round(np.std(precision_val), 3)\n",
    "    std_recall_train = round(np.std(recall_train), 3)\n",
    "    std_recall_val = round(np.std(recall_val), 3)\n",
    "\n",
    "    # Final Predictions using Soft Voting\n",
    "    final_test_preds = np.argmax(test_preds / method.get_n_splits(), axis=1)\n",
    "    test_RS['Claim Injury Type'] = final_test_preds \n",
    "\n",
    "    test_RS['Claim Injury Type'] = test_RS['Claim Injury Type'].replace(label_mapping)\n",
    "    \n",
    "    predictions = test_RS['Claim Injury Type']\n",
    "    \n",
    "    if file_name != None:\n",
    "    \n",
    "        predictions.to_csv(f'./pred/corrected_k_fold/{file_name}.csv')\n",
    "\n",
    "\n",
    "    # Return data and treated Test_RS\n",
    "    return {\n",
    "        'avg_time': str(avg_time) + '+/-' + str(std_time),\n",
    "        'avg_f1_train': str(avg_f1_train) + '+/-' + str(std_f1_train),\n",
    "        'avg_f1_val': str(avg_f1_val) + '+/-' + str(std_f1_val),\n",
    "        'avg_precision_train': str(avg_precision_train) + '+/-' + str(std_precision_train),\n",
    "        'avg_precision_val': str(avg_precision_val) + '+/-' + str(std_precision_val),\n",
    "        'avg_recall_train': str(avg_recall_train) + '+/-' + str(std_recall_train),\n",
    "        'avg_recall_val': str(avg_recall_val) + '+/-' + str(std_recall_val),\n",
    "        'test_data': test_RS,\n",
    "        'predictions': predictions\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T17:56:04.338780Z",
     "start_time": "2024-12-14T17:56:04.169279Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the DataFrame into features (X) and target variable (y)\n",
    "X = df.drop('Claim Injury Type', axis=1) \n",
    "y = df['Claim Injury Type']  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stratified K-Fold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T18:01:57.330936Z",
     "start_time": "2024-12-14T18:01:57.328429Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T18:31:34.255292Z",
     "start_time": "2024-12-14T18:01:57.723768Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Fold took 1.23 minutes\n",
      "This Fold took 1.23 minutes\n",
      "This Fold took 1.23 minutes\n",
      "This Fold took 1.24 minutes\n",
      "This Fold took 1.26 minutes\n",
      "This Fold took 3.59 minutes\n",
      "This Fold took 3.54 minutes\n",
      "This Fold took 3.58 minutes\n",
      "This Fold took 3.6 minutes\n",
      "This Fold took 3.54 minutes\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022895 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2522\n",
      "[LightGBM] [Info] Number of data points in the train set: 459220, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -3.828846\n",
      "[LightGBM] [Info] Start training from score -0.679083\n",
      "[LightGBM] [Info] Start training from score -2.119944\n",
      "[LightGBM] [Info] Start training from score -1.352037\n",
      "[LightGBM] [Info] Start training from score -2.475656\n",
      "[LightGBM] [Info] Start training from score -4.914913\n",
      "[LightGBM] [Info] Start training from score -8.680576\n",
      "[LightGBM] [Info] Start training from score -7.107696\n",
      "This Fold took 1.09 minutes\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025408 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2526\n",
      "[LightGBM] [Info] Number of data points in the train set: 459220, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -3.828846\n",
      "[LightGBM] [Info] Start training from score -0.679083\n",
      "[LightGBM] [Info] Start training from score -2.119926\n",
      "[LightGBM] [Info] Start training from score -1.352037\n",
      "[LightGBM] [Info] Start training from score -2.475656\n",
      "[LightGBM] [Info] Start training from score -4.915210\n",
      "[LightGBM] [Info] Start training from score -8.680576\n",
      "[LightGBM] [Info] Start training from score -7.107696\n",
      "This Fold took 1.09 minutes\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022522 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2519\n",
      "[LightGBM] [Info] Number of data points in the train set: 459220, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -3.828946\n",
      "[LightGBM] [Info] Start training from score -0.679083\n",
      "[LightGBM] [Info] Start training from score -2.119926\n",
      "[LightGBM] [Info] Start training from score -1.352037\n",
      "[LightGBM] [Info] Start training from score -2.475656\n",
      "[LightGBM] [Info] Start training from score -4.914913\n",
      "[LightGBM] [Info] Start training from score -8.680576\n",
      "[LightGBM] [Info] Start training from score -7.107696\n",
      "This Fold took 1.09 minutes\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025184 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2528\n",
      "[LightGBM] [Info] Number of data points in the train set: 459220, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -3.828846\n",
      "[LightGBM] [Info] Start training from score -0.679079\n",
      "[LightGBM] [Info] Start training from score -2.119926\n",
      "[LightGBM] [Info] Start training from score -1.352046\n",
      "[LightGBM] [Info] Start training from score -2.475656\n",
      "[LightGBM] [Info] Start training from score -4.914913\n",
      "[LightGBM] [Info] Start training from score -8.693479\n",
      "[LightGBM] [Info] Start training from score -7.107696\n",
      "This Fold took 1.12 minutes\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022323 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2521\n",
      "[LightGBM] [Info] Number of data points in the train set: 459220, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -3.828846\n",
      "[LightGBM] [Info] Start training from score -0.679079\n",
      "[LightGBM] [Info] Start training from score -2.119926\n",
      "[LightGBM] [Info] Start training from score -1.352046\n",
      "[LightGBM] [Info] Start training from score -2.475656\n",
      "[LightGBM] [Info] Start training from score -4.914913\n",
      "[LightGBM] [Info] Start training from score -8.693479\n",
      "[LightGBM] [Info] Start training from score -7.107696\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "This Fold took 1.08 minutes\n"
     ]
    }
   ],
   "source": [
    "run_XGB = mod.k_fold(skf, X, y, 'XGB', test1)\n",
    "run_RF = mod.k_fold(skf, X, y, 'RF', test1)\n",
    "run_LGBM = mod.k_fold(skf, X, y, 'LGBM', test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T18:31:34.337802Z",
     "start_time": "2024-12-14T18:31:34.275898Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGB</th>\n",
       "      <th>RF</th>\n",
       "      <th>LGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train F1 macro</th>\n",
       "      <td>0.67+/-0.001</td>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.42+/-0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation F1 macro</th>\n",
       "      <td>0.451+/-0.007</td>\n",
       "      <td>0.392+/-0.004</td>\n",
       "      <td>0.394+/-0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision Train</th>\n",
       "      <td>0.836+/-0.001</td>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.493+/-0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision Validation</th>\n",
       "      <td>0.572+/-0.009</td>\n",
       "      <td>0.531+/-0.015</td>\n",
       "      <td>0.445+/-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall Train</th>\n",
       "      <td>0.654+/-0.0</td>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.423+/-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall Validation</th>\n",
       "      <td>0.432+/-0.007</td>\n",
       "      <td>0.377+/-0.002</td>\n",
       "      <td>0.398+/-0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>1.238+/-0.012</td>\n",
       "      <td>3.57+/-0.025</td>\n",
       "      <td>1.094+/-0.014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                XGB             RF           LGBM\n",
       "Train F1 macro         0.67+/-0.001      1.0+/-0.0   0.42+/-0.013\n",
       "Validation F1 macro   0.451+/-0.007  0.392+/-0.004  0.394+/-0.007\n",
       "Precision Train       0.836+/-0.001      1.0+/-0.0  0.493+/-0.022\n",
       "Precision Validation  0.572+/-0.009  0.531+/-0.015   0.445+/-0.01\n",
       "Recall Train            0.654+/-0.0      1.0+/-0.0   0.423+/-0.02\n",
       "Recall Validation     0.432+/-0.007  0.377+/-0.002  0.398+/-0.011\n",
       "Time                  1.238+/-0.012   3.57+/-0.025  1.094+/-0.014"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [run_XGB, run_RF, run_LGBM]\n",
    "m.metrics2(models, ['XGB', 'RF', 'LGBM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T18:31:46.223622Z",
     "start_time": "2024-12-14T18:31:34.339795Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/mm/fxsq_1490x9dd2w76tqvt3kr0000gn/T/tmpwt93ax0l.wav':\n",
      "  Duration: 00:00:10.00, bitrate: 1536 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, 2 channels, s16, 1536 kb/s\n",
      "   9.95 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import play_song as s\n",
    "s.play_('audio.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Final Predictions\n",
    "\n",
    "<a href=\"#top\">Top &#129033;</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T17:08:09.995887Z",
     "start_time": "2024-12-13T17:08:09.611901Z"
    }
   },
   "outputs": [],
   "source": [
    "test_filtered = test_RS[X_train_RS.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T17:08:11.755463Z",
     "start_time": "2024-12-13T17:08:10.901764Z"
    }
   },
   "outputs": [],
   "source": [
    "test_filtered['Claim Injury Type'] = model.predict(test_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map Predictions to Original Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T17:08:12.639638Z",
     "start_time": "2024-12-13T17:08:12.578073Z"
    }
   },
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    0: \"1. CANCELLED\",\n",
    "    1: \"2. NON-COMP\",\n",
    "    2: \"3. MED ONLY\",\n",
    "    3: \"4. TEMPORARY\",\n",
    "    4: \"5. PPD SCH LOSS\",\n",
    "    5: \"6. PPD NSL\",\n",
    "    6: \"7. PTD\",\n",
    "    7: \"8. DEATH\"\n",
    "}\n",
    "\n",
    "\n",
    "test_filtered['Claim Injury Type'] = test_filtered['Claim Injury Type'].replace(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T17:08:13.137078Z",
     "start_time": "2024-12-13T17:08:13.102172Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Claim Injury Type\n",
       "2. NON-COMP        315388\n",
       "4. TEMPORARY        53658\n",
       "3. MED ONLY          9816\n",
       "1. CANCELLED         6746\n",
       "5. PPD SCH LOSS      2332\n",
       "8. DEATH               35\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count unique values in column 'Claim Injury Type'\n",
    "test_filtered['Claim Injury Type'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T17:08:13.910086Z",
     "start_time": "2024-12-13T17:08:13.903482Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract the target variable 'Claim Injury Type' from the test dataset for prediction\n",
    "predictions = test_filtered['Claim Injury Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T17:08:35.639736Z",
     "start_time": "2024-12-13T17:08:35.295199Z"
    }
   },
   "outputs": [],
   "source": [
    "# Assign a descriptive name for easy reference\n",
    "name = 'all_feat_scaled_XGB_5f_2'\n",
    "\n",
    "# Save the predictions to a CSV file.\n",
    "predictions.to_csv(f'./pred/{name}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
