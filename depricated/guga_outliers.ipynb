{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"top\"></a>\n",
    "\n",
    "** **\n",
    "\n",
    "# 1. Importing Libraries & Data\n",
    "In this section, we set up the foundation for our project by importing the necessary Python libraries and loading the dataset. These libraries provide the tools for data manipulation, visualization, and machine learning modeling throughout the notebook. Additionally, we import the historical claims dataset, which forms the core of our analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Train-Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import preproc as p\n",
    "\n",
    "# fs\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import feature_selection as fs\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Suppress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "df = pd.read_csv('train_data_EDA.csv', index_col = 'Claim Identifier')\n",
    "\n",
    "# Load testing data\n",
    "test = pd.read_csv('test_data_EDA.csv', index_col = 'Claim Identifier')\n",
    "\n",
    "# Display the first 3 rows of the training data\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train-Test Split\n",
    "The train-test split is a crucial technique used to assess model performance by dividing the dataset into training and testing subsets. This ensures that the model is evaluated on unseen data, helping to prevent overfitting and providing an unbiased performance estimate. \n",
    "\n",
    "<a href=\"#top\">Top &#129033;</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Holdout Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the DataFrame into features (X) and target variable (y)\n",
    "X = df.drop('Claim Injury Type', axis=1)\n",
    "y = df['Claim Injury Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.isnull().sum())  # Check missing values in features\n",
    "print(y.isnull().sum())  # Check missing values in the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42,\n",
    "                                                    stratify = y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Missing Values\n",
    "\n",
    "<a href=\"#top\">Top &#129033;</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Birth Year**\n",
    "\n",
    "To fill the missing values, we will start by creating a mask, which filters for observations where **Age at Injury** and **Accident Date Year** are not missing, and when **Birth Year** is either missing or zero. Since we are going to use **Age at Injury** and **Accident Date Year** to compute **Birth Year**, ensuring those two variables are no missing is crucial. Then, we also decided to recompute the **Birth Year** where it is 0, since it is impossible to have 0 as a **Birth Year**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = X_train['Accident Date Year'].notna() & X_train['Age at Injury'].notna() & \\\n",
    "           (X_train['Birth Year'].isna() | (X_train['Birth Year'] == 0))\n",
    "\n",
    "\n",
    "val_mask = (X_val['Accident Date Year'].notna() &  X_val['Age at Injury'].notna() &  \n",
    "    (X_val['Birth Year'].isna() | (X_val['Birth Year'] == 0)))\n",
    "\n",
    "test_mask = test['Accident Date Year'].notna() & test['Age at Injury'].notna() & \\\n",
    "           (test['Birth Year'].isna() | (test['Birth Year'] == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.loc[train_mask, 'Birth Year'] = X_train['Accident Date Year'] - X_train['Age at Injury']\n",
    "\n",
    "X_val.loc[val_mask, 'Birth Year'] = X_val['Accident Date Year'] - X_val['Age at Injury']\n",
    "\n",
    "test.loc[test_mask, 'Birth Year'] = test['Accident Date Year'] - test['Age at Injury']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Average Weekly Wage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Average Weekly Wage'] = p.ball_tree_impute(X_train, 'Average Weekly Wage', n_neighbors=100)\n",
    "\n",
    "X_val['Average Weekly Wage'] = p.ball_tree_impute(X_val, 'Average Weekly Wage', n_neighbors=100)\n",
    "\n",
    "test['Average Weekly Wage'] = p.ball_tree_impute(test, 'Average Weekly Wage', n_neighbors=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Outliers\n",
    "\n",
    "<a href=\"#top\">Top &#129033;</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Detection\n",
    "\n",
    "To detect outliers we will use a function that plots boxplots and identifies outliers based on the Interquartile Range method. This function will also add to a list all columns with a higher percentage of outliers than a previously set threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.detect_outliers_iqr(X_train, 0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing With Outliers\n",
    "\n",
    "Here we will apply some techniques to attempt to deal with outliers, either by applying some transformations or removing them. Our goal is to not remove more than 5% of observations. To keep track of this metrics, we will start by saving the initial length of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_copy = X_train.copy()\n",
    "X_train_len = len(X_train_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(data, columns):\n",
    "    outliers_removed = {}\n",
    "    \n",
    "    for column in columns:\n",
    "        Q1 = data[column].quantile(0.25)\n",
    "        Q3 = data[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        # Count outliers before treatment\n",
    "        initial_outliers = data[\n",
    "            (data[column] < lower_bound) | (data[column] > upper_bound)\n",
    "        ].shape[0]\n",
    "        \n",
    "        # Outlier treatment based on variable type\n",
    "        if column in ['Age at Injury', 'Average Weekly Wage', 'Birth Year', 'C-2 Date Year', 'Accident Date Year']:\n",
    "            data = data[\n",
    "                (data[column] >= lower_bound) & \n",
    "                (data[column] <= upper_bound)\n",
    "            ]\n",
    "        elif column in ['IME-4 Count', 'Industry Code', 'Alternative Dispute Resolution Bin']:\n",
    "            data[column] = winsorize(data[column], limits=[0.05, 0.05])\n",
    "        \n",
    "        # Count outliers after treatment\n",
    "        final_outliers = data[\n",
    "            (data[column] < lower_bound) | (data[column] > upper_bound)\n",
    "        ].shape[0]\n",
    "        \n",
    "        # Record outliers removed\n",
    "        outliers_removed[column] = initial_outliers - final_outliers\n",
    "\n",
    "    return data, outliers_removed\n",
    "\n",
    "variables_to_treat = [\n",
    "    'Age at Injury', \n",
    "    'Average Weekly Wage', \n",
    "    'Birth Year', \n",
    "    'IME-4 Count', \n",
    "    'Industry Code', \n",
    "    'Alternative Dispute Resolution Bin', \n",
    "    'Accident Date Year', \n",
    "    'C-2 Date Year'\n",
    "]\n",
    "\n",
    "data_cleaned, outliers_summary = remove_outliers(X_train_copy, variables_to_treat)\n",
    "\n",
    "for var, count in outliers_summary.items():\n",
    "    print(f\"{var}: {count} outliers removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_outliers_after_treatment(df, treated_df, variables, missing_threshold):\n",
    "    bounds = {}\n",
    "    missing_col = []\n",
    "    \n",
    "    for column in variables:\n",
    "        Q1 = treated_df[column].quantile(0.25)\n",
    "        Q3 = treated_df[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        bounds[column] = {'lower_bound': lower_bound, 'upper_bound': upper_bound}\n",
    "\n",
    "        outlier_data = treated_df[(treated_df[column] < lower_bound) | (treated_df[column] > upper_bound)]\n",
    "        missing = len(outlier_data) / len(treated_df) * 100\n",
    "        \n",
    "        print(f'Column: {column} - Number of Outliers (After Treatment): {len(outlier_data)}')\n",
    "        print(f'Column: {column} - % of Outliers (After Treatment): {missing:.2f}% \\n')\n",
    "        \n",
    "        if missing > missing_threshold:\n",
    "            missing_col.append(column)\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.boxplot(data=treated_df, x=column, color='orange', showfliers=False)\n",
    "        sns.stripplot(data=outlier_data, x=column, color='red', jitter=True, label='Outliers')\n",
    "        plt.title(f'Boxplot with Outliers for {column} (After Treatment)')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    print(f'Columns with more than {missing_threshold}% Outliers After Treatment:')\n",
    "    print(missing_col)\n",
    "    \n",
    "    return bounds\n",
    "\n",
    "variables_to_check = [\n",
    "    'Age at Injury', \n",
    "    'Average Weekly Wage', \n",
    "    'Birth Year', \n",
    "    'IME-4 Count', \n",
    "    'Industry Code', \n",
    "    'Alternative Dispute Resolution Bin', \n",
    "    'Accident Date Year', \n",
    "    'C-2 Date Year'\n",
    "]\n",
    "\n",
    "bounds_after_treatment = check_outliers_after_treatment(X_train_copy, data_cleaned, variables_to_check, missing_threshold=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Feature Selection\n",
    "\n",
    "<a href=\"#top\">Top &#129033;</a>\n",
    "\n",
    "In this section we will perform feature selection. We will start by splitting data into numeric, categorical or max 3 classes. Then, scaling will be applied. However, from the previous delivery we noted that the best performing models are Tree-Based, which are not sensitive to feature's scale, and therefore do not require scaling. Consequently, we will implement the same method for both scaled and unscaled numerical data, and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variable type split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = ['Age at Injury', 'Average Weekly Wage', 'Birth Year', 'IME-4 Count', 'Number of Dependents',\n",
    "       'Accident Date Year', 'Accident Date Month', 'Accident Date Day', 'Assembly Date Year', \n",
    "       'Assembly Date Month', 'Assembly Date Day', 'C-2 Date Year', 'C-2 Date Month', 'C-2 Date Day',\n",
    "       'IME-4 Count Log', 'IME-4 Count Double Log']\n",
    "\n",
    "max3_class = ['Attorney/Representative Bin', 'Carrier Type_1A. PRIVATE', 'Carrier Type_2A. SIF',\n",
    "              'Carrier Type_3A. SELF PUBLIC', 'Carrier Type_4A. SELF PRIVATE', 'COVID-19 Indicator Enc',\n",
    "              'Gender Enc', 'Gender_F', 'Gender_M', 'Zip Code Valid', 'Age Group', 'C-3 Date Binary',\n",
    "              'First Hearing Date Binary']\n",
    "\n",
    "categ = ['Industry Code', 'WCIO Cause of Injury Code', 'WCIO Nature of Injury Code',\n",
    "         'WCIO Part Of Body Code', 'Carrier Name Enc', 'Carrier Type freq', 'County of Injury freq',\n",
    "         'District Name freq', 'Medical Fee Region freq', 'Accident Date Day of Week', 'Assembly Date Day of Week',\n",
    "         'C-2 Date Day of Week', 'WCIO Codes', 'Industry Sector Count Enc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the numerical features in the training set using RobustScaler\n",
    "X_train_num_RS = robust.fit_transform(X_train[num])\n",
    "X_train_num_RS = pd.DataFrame(X_train_num_RS, columns=num, index=X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the numerical features in the validation set using the fitted RobustScaler\n",
    "X_val_num_RS = robust.transform(X_val[num])\n",
    "X_val_num_RS = pd.DataFrame(X_val_num_RS, columns=num, index=X_val.index)\n",
    "\n",
    "# Scaling the numerical features in the test set using the same fitted RobustScaler\n",
    "test_num_RS = robust.transform(test[num])\n",
    "test_num_RS = pd.DataFrame(test_num_RS, columns=num, index=test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all_categ = pd.concat([X_train[categ], X_train[max3_class]], axis=1)\n",
    "X_val_all_categ = pd.concat([X_val[categ], X_val[max3_class]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Filter-Based Methods\n",
    "\n",
    "<a href=\"#top\">Top &#129033;</a>\n",
    "\n",
    "Filter-based methods evaluate the relevance of features independently of the model using statistical measures like correlation, Chi-square tests, and mutual information. This section explores how these methods help reduce dimensionality, improve model performance, and prevent overfitting by selecting the most informative features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variance Threshold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.1\n",
    "\n",
    "# Initialize the VarianceThreshold selector with the specified threshold\n",
    "selector = VarianceThreshold(threshold=threshold)\n",
    "\n",
    "# Apply the selector to the scaled training data (X_train_RS) to retain only the high-variance features\n",
    "X_train_high_variance = selector.fit_transform(X_train[num])\n",
    "\n",
    "# Print the number of features before applying the variance threshold\n",
    "print(f\"Number of features before variance threshold: {X_train[num].shape[1]}\")\n",
    "\n",
    "# Print the number of features after applying the variance threshold\n",
    "print(f\"Number of features after variance threshold: {X_train_high_variance.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spearman Correlation Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the correlation matrix to identify relationships between numerical features\n",
    "fs.correlation_matrix(X_train[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def chi_squared(X_categ, y, threshold=0.05):\n",
    "\n",
    "    # Fit the chi-squared selector\n",
    "    chi2_selector = SelectKBest(chi2, k='all')\n",
    "    chi2_selector.fit(X_categ, y)\n",
    "\n",
    "    # Get Chi-squared scores and p-values\n",
    "    chi2_scores = chi2_selector.scores_\n",
    "    p_values = chi2_selector.pvalues_\n",
    "\n",
    "    # Create a DataFrame for scores and p-values\n",
    "    scores_df = pd.DataFrame({\n",
    "        'Feature': X_categ.columns,\n",
    "        'Chi2 Score': chi2_scores,\n",
    "        'p-value': p_values\n",
    "    })\n",
    "\n",
    "    # Filter features based on the p-value threshold\n",
    "    selected_features = scores_df[scores_df['p-value'] < threshold]['Feature']\n",
    "    \n",
    "    # Extract non-selected features\n",
    "    non_selected_features = scores_df[scores_df['p-value'] >= threshold]\n",
    "\n",
    "    # Plot the Chi-squared scores\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Chi2 Score', y='Feature', data=scores_df.sort_values(by='Chi2 Score', ascending=False), color='orange')\n",
    "    plt.axvline(x=threshold, color='red', linestyle='--', label=f'p-value Threshold = {threshold}')\n",
    "    plt.title('Chi-squared Scores for Features')\n",
    "    plt.xlabel('Chi-squared Score')\n",
    "    plt.ylabel('Features')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nInitial Features: {len(X_categ.columns.tolist())}\\n\")\n",
    "    print(X_categ.columns.tolist())\n",
    "    print(f\"\\nDecision for Categorical Features (p-value < threshold): {len(selected_features.tolist())}\\n\")\n",
    "    print(selected_features.tolist())\n",
    "\n",
    "    # Display non-selected features with their p-values and Chi-squared scores\n",
    "    print(\"\\nNon-Selected Features (p-value >= threshold):\\n\")\n",
    "    print(non_selected_features[['Feature', 'Chi2 Score', 'p-value']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_squared(X_train[categ], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Wrapper Methods\n",
    "\n",
    "<a href=\"#top\">Top &#129033;</a>\n",
    "\n",
    "Unlike filter methods, which assess features independently, wrapper methods evaluate the effectiveness of feature subsets by measuring the model’s performance, making them more computationally expensive but often more accurate in selecting relevant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Embedded Methods\n",
    "\n",
    "<a href=\"#top\">Top &#129033;</a>\n",
    "\n",
    "These methods use algorithms that inherently select features as part of the model’s learning process. Embedded methods are computationally efficient and tend to be more accurate than filter methods, as they consider feature interactions and model performance simultaneously.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM2425",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
